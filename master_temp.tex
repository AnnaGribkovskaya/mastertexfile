\documentclass[twoside,english]{uiofysmaster}
\geometry{a4paper,includeall,bindingoffset=0cm,margin=3cm,
            marginparsep=0cm,marginparwidth=0cm,top=2cm}
\usepackage{braket}
\usepackage{mathtools}      
\usepackage{amsmath} 
\usepackage{listings}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}
\usepackage{tcolorbox}
\author{Anna Gribkovskaya}
\title{\uppercase{Semi-stochastic Coupled Cluster Doubles for Quantum Dots}}
\date{May 2018}
\usepackage{pdfpages}
\usepackage{mathrsfs}
\usepackage{simpler-wick}
\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{post}{Postulate}
\usepackage{bm}
\newcommand{\bmat}[2]{\begin{bmatrix}[#1] #2 \end{bmatrix}} 
\usepackage[backend=bibtex]{biblatex}
\addbibresource{master.bib} 



\begin{document}

\begin{titlepage}
\maketitle
\end{titlepage}
\begin{abstract}
	This is an abstract text.
\end{abstract}

\begin{dedication}
	To someone
	\\\vspace{12pt}
	This work is dedicated to my family. Thank you all for bearing with my while I was writing it.
\end{dedication}
\begin{acknowledgements}
	I acknowledge my acknowledgements.
\end{acknowledgements}
\tableofcontents

%\chapter{}
\chapter*{Introduction}
This thesis is devoted to study of Quantum Dots (QDs). The detailed mathematical description of QDs is provided below, but in the most general way one may say that QDs are man-made devices that are small enough to posses quantum properties, such as energy shell structure, tunneling effect and etc. Most commonly such devices are fabricated using semiconductors and their size vary from few nanometers to hundreds of nanometers (one nanometer or nm is equal to $1\times 10^{-9} m$). In literature one may find name "artificial atoms" when referring to such  semiconductor nanostructures. This name reflect the fact that QDs and atoms share many similar properties, however this is not completely legit name, though QD are larger then atoms. For atoms size is usually measured in picometres  (one picometre or pm is equal to $1\times 10^{-12} m$).  Normal size of an atom vary form 53 pm for hydrogen atom (this quantity is also known as Bohr radius), to  273 pm for cesium (which is considered to be one of the largest atoms). As one can mention even the small QDs correspond 10 atoms in diameter. Apart from this QDs are very similar to the atoms. The name Quantum Dot reflect the fact that we have a structure that is small enough to have quantum properties and also that this structure is spatially localized. The properties of QDs lie between those of individual discrete atoms or molecules and bulk semiconductors. This fact make such particles matter of great interest both for science and industry. Below in chapter (!!!!!!!) one can find a brief history of QDs and also  some of their applications.  \\
The aim of this thesis is to study QD numerically. 

	SHOULD ADD MORE LATELY!!! And do not forget reference to chapters afterwards!!
	
\part{Theory}
\chapter{Quantum mechanics}
In the end of 19th century physics had some unsolved problems that couldn't be tackled using already developed theories and methods. This had led to a  significantly different theory with a number of essential distinctions  from that developed before. This new theory was named quantum mechanics. In the classical (or Newtonian mechanics) there is a theoretical possibility to obtain a complete knowledge of the system under consideration. In quantum mechanics this is not possible, neither for some particular moment in time  nor for all other  moments in time. \\
Let's introduce some concepts here. The \textbf{uncertainty principle} and the \textbf{probability interpretation of the wave function}. The  uncertainty principle (or Heisenberg's uncertainty principle) puts a limit on the precision of our measurement of some particular pairs of physical quantities (e.i. position and momentum). The probability interpretation of the wave function is a bit harder to explain, because one needs a proper mathematical description of the quantum mechanics to understand this. For now we just say that if we consider one single particle in space the probability of finding it in some certain position is related to the wave function. We will derive the expression for the total wave function of the system later in this thesis. Another 
substantial difference is associated with so-called \textbf{principle of complementarity}. It was formulated by  Niels Bohr, one of the founders of the quantum mechanics. It stands that in order to describe a system we need a pair of certain complementary properties which cannot be observed simultaneously. A good example of such a pair are wave and particle properties of light or electrons. Classical mechanics considered light as a wave and electron as a particle, but this approach failed to explain the photoelectric effect and the diffraction of electrons on a slit. Moreover, position and momentum of the particle also can be considered as a pair of complementary properties. This makes Bohr's principle of the complementarity closely connected to Heisenberg's uncertainty principle. Also one should mention that quantum mechanics allows us to change the number of particles in some particular state. For example, we have a \textbf{creation} operator which increases the number of particles in some given state of the system by one, and \textbf{annihilation} operator which decreases this number by one. The last concept to be mentioned here is the word \textbf{quantum} itself. In physics, "quantum" determines the smallest possible difference between two values or minimal amount of quantity involved in an interaction. This concept is associated with the revolutionary supposition made by Max Planck back in 1900. He assumed that electromagnetic energy could be emitted in a form of some discrete quantities, known as “quantum”. He also introduced a proportionality coefficient for a minimal energy difference, so-called Planck's constant $h = 6.626 \times 10^{-34} \text{ } (kg \cdot m^2\cdot s^{-1})$. As one can see it has a very small value.  \\
How does it possible to have two theories much different from each other and continue to use both of them? This is perfectly fine even it may seems to be a bit contradictory. In science there is a rule that require for any new theory to agree with the previous ones under some conditions. This rule is called a \textbf{correspondence principle}. In case of quantum mechanics these conditions are named \textbf{classical limit} or \textbf{correspondence limit}. In particular this means that quantum mechanical description of the system should correspond to those obtained by classical theory for large quantum numbers. Mathematically it can be achieved by requirement $h \rightarrow 0$, where $h$ Planck's constant. This principle allows us to determine whether a specific quantum theory is valid or not.\\
Today we usually say that classical mechanics describes the macroscopic objects and quantum mechanics describes microscopic ones. This arise from the fact that some quantum effects can be observed only for extremely small particles. However this is not enough to describe the difference, because even the observation itself is now different from that in classical physics. 
For more details on the matter, please refer to \cite{phillipsIntroductionQuantumMechanics2003}. \\


\section{Quantum theory}
In this section we provide a brief description of main assumptions needed for the quantum theory and  some basic notations to be used in the thesis.\\
As it has been already mentioned quantum theory has been developed though the $20^{\text{th}}$ century. As any other new theory it is based on some assumptions called the postulates of quantum mechanics (QM). In this thesis we do not aim to provide a detailed description on the topic, however some basic introduction is needed.\\

\begin{defn} Hilbert Space.\\
	Let $\mathscr{H}$ be a complex vector space. The inner product $\braket{\alpha|\beta} $\footnote{$\ket{\alpha}$ and  $\ket{\beta}$ are ket-vectors in Dirac notations.} in that space is defined so that it has the following properties:
	\begin{enumerate}		
		\item $\braket{a\alpha|\beta} = a\braket{\alpha|\beta}$, $a \in C$.
		\item $\braket{\alpha|b\beta} = b^{*}\braket{\alpha|\beta}$, $b \in C$.
		\item $\overline{\braket{\alpha|\beta}} =\braket{\beta|\alpha}$.
		\item $||\alpha||^2= \braket{\alpha|\alpha} \geq 0 $.			
	\end{enumerate}
\end{defn}

\begin{post}
	Every instant state of a system is represented by a vector in Hilbert space $\mathscr{H}$.\\
\textit{Comment}. This is a very strong demand, because it means that any superposition of the different states is also a state of the system. For example, if $\ket{\alpha_1}$ and  $\ket{\alpha_2}$ are vectors describing possible states of the system, then their linear combination $\ket{\alpha}$ is also a state of the same system:
\begin{equation*}
\ket{\alpha}=a_1\ket{\alpha_1}+a_2\ket{\alpha_2}, \text{   } a_1\text{  and }  a_2 \in C.
\end{equation*}
\end{post}
\begin{defn}
Operator $\hat{Q}$ is Hermitian if it satisfies the equation:
\begin{equation}
\hat{Q}^\dagger=\hat{Q},
\end{equation}
where $\hat{Q}^\dagger$ is adjoint of $\hat{Q}$.
\end{defn}
\begin{post}\label{postulat2}
	Every physical observable is associated with an operator $\hat{Q}$ in a Hilbert space. Action of the operator on state vector results into following eigenvalue equation:
	\begin{equation}\label{eq:general_eigval eq}
	\hat{Q}\ket{\alpha}= q\ket{\alpha}, 
	\end{equation}
where eigenvalues $q$ are the only measurable values associated with the operator. Eigenvectors determine a complete orthonormal set of vectors for this operator. In addition every operator $\hat{Q}$ associated with a measurable physical quantity must be a linear Hermitian operator. In particular that means it should posses the following properties:
	\begin{align}
	&\hat{Q}^\dagger=\hat{Q},\\
	&(a\hat{Q})^\dagger=a^*\hat{Q}^\dagger,\\
	&(\hat{Q}\hat{P})^\dagger  =\hat{P}^\dagger \hat{Q}^\dagger,\\
	&(\hat{Q}+\hat{P})^\dagger =\hat{Q}^\dagger+\hat{P}^\dagger,
	\end{align}
	where $a \in C$, and * denote complex conjugate.\\
\textit{Comment}. The eigenvalue equation ($\ref{eq:general_eigval eq}$) has interesting properties when $\hat{Q}$ is Hermitian operator. They are presented in theorems below.
\end{post}

\begin{theorem}\label{theorem:eigvalHerm}
	Set of eigenvalues of any Hermitian operator $\hat{Q}$ on Hilbert space $\mathscr{H}$ is set of real numbers. 
\end{theorem}

\begin{theorem}\label{theorem:eigvecHerm}
	Eigenvectors of any Hermitian operator $\hat{Q}$ on Hilbert space $\mathscr{H}$ that belong to different eigenvalues are orthogonal. 
\end{theorem}

\begin{theorem}\label{theorem:orhtonormalbasis}
Set of eigenvectors of any Hermitian operator $\hat{Q}$ on Hilbert space $\mathscr{H}$ can be chosen to be an orthonormal basis for $\mathscr{H}$.
\end{theorem}
We do not provide proofs for these Theorems. For more detailed description please refer to \cite{aulettaQuantumMechanics2009}.
\begin{post}
	Let $\mathscr{H}_1$ and $\mathscr{H}_2$ be the Hilbert spaces corresponding to two systems. The Hilbert space of joint system is given by tensor product $\mathscr{H}=\mathscr{H}_1 \otimes \mathscr{H}_2$.\\
\textit{Comment}. As it is shown further in this thesis this postulate provides a method to describe many-particle systems. 
\end{post}
\begin{post}
The time evolution of the quantum mechanical system is given by the Schr\"{o}dinger equation:
\begin{equation}\label{eq:basic_schrod}
 i \hbar \frac{\partial }{ \partial t}\ket{\Psi} = \hat{H}\ket{\Psi},
\end{equation}
where $\ket{\Psi}=\ket{\Psi(t)}$ .
\end{post}
In this thesis we do not consider time-evolution of the system and will be focused on the time-independent Schr\"{o}dinger equation or stationary-state equation:
\begin{equation}
\hat{H}\ket{\Psi} = E \ket{\Psi},
\end{equation}
where $\hat{H}$ in Hamiltonian, $\ket{\Psi}$ is state vector of the system and $E$ is the expectation value of the energy. It is the energy spectrum we are interested in, so before solving the Schr\"{o}dinger equation we need to agree on the form of Hamiltonian and also construct the state vector. This is presented in the sections below.


\subsection{Many-Body problem formulation}

As it has been already mentioned all state functions arethe  vectors in the Hilbert space. When we deal with a system consisting of many particles we need to define the type of these particles. Bosons are the particles with an integer spin and fermions are the particles with an odd half-integer spin. State vectors of these particles belong to different Hilbert spaces and should be studied independently. In this thesis we consider electrons which are fermions and must obey an exclusion principle, formulated by Wolfgang Pauli in 1925.
\begin{defn}The Pauli exclusion principle.\\
Two or more identical fermions cannot occupy the same quantum state simultaneously in the same system.
\end{defn}
Let's take a closer look at the total wave function and how this principle affect the permutations of the particles withing the system. First we need to mention that the particles are identical and indistinguishable. In quantum mechanics interacting and identical particles are considered indistinguishable, which is different from classical mechanics where all particles are distinguishable. The concept of indistinguishability requires some discussion about what happens to the wave function if we interchange the particles? At this point a difference between bosons and fermions becomes a significant issue. \\
In order to make a proper mathematical description and be able to drive properties of wave functions we need to define a new operator for permutation of the particles.\\
\begin{defn}\label{denf:permutation}
Let $\hat{P_{ij}}$ be the operator that interchanges particles $i$ and $j$. 
\[\hat{P_{ij}} \ket{ \Psi(x_1 ... x_i ... x_j ...) }=\ket{ \Psi(x_1 ... x_j ... x_i ...) } \]
\end{defn}
\begin{theorem} Hermiticity of the permutation operator.\\
	$\hat{P_{ij}}$ is a Hermitian operator in Hilbert space for identical particles.\\
	So that $\hat{P_{ij}}^{-1}=\hat{P_{ij}}^\dagger$.
\end{theorem}
Considering this property one may define and solve the eigenvalue equation for the permutation operator.
\begin{eqnarray}
\hat{P_{ij}}\ket{\Psi}=\epsilon_{ij}\ket{\Psi},\\
\hat{P_{ij}}\hat{P_{ij}}\ket{\Psi}= \epsilon_{ij}^2 \ket{\Psi},\\
\epsilon_{ij}^2 =1 \rightarrow \epsilon_{ij} = \pm 1.
\end{eqnarray}
\begin{defn}Symmetricity of wave function.\\
If $\epsilon_{ij}=1$,  $\ket{\Psi}$ considered to be symmetric. In this case it corresponds to bosons.\\
If $\epsilon_{ij}=-1$,  $\ket{\Psi}$ considered to be antisymmetric. In this case it corresponds to fermions.
\end{defn}
The permutation operator is used in Chapter $\ref{ch:HF}$ for construction of total many fermion wave function and in Chapter $\ref{ch:coupled_cluster}$ for amplitudes.
\subsubsection{The Hamiltonian of many-body system} \label{sec:manybody}
As it has been already mentioned Hamiltonian is a Hermitian operator. It can be expressed as follows:
\begin{equation}
\hat{H}=\hat{T}+\hat{V},
\end{equation}
where $\hat{T}$ is the kinetic energy operator and $\hat{V}$ is the potential energy operator. \\
Here we assume the electrons are confined by a pure isotropic harmonic oscillator (H.O.) potential. Also in this thesis we consider closed shell systems. It means that all possible single-particle states below a certain level are occupied. Such level often called a Fermi level of the system. In particular this assumption means that addition or removal of one electron to such system requires more energy than same the action in a system with non-occupied lowest levels. 
%That leads to a given number of particles $N = \{2, 6, 12, 20\}$ we may have in our quantum dot. 
Using natural units ($\hbar=c=e=m_e=1$) one can write Hamiltonian of a such system in Cartesian coordinates as
\begin{equation}
\label{eq:finalH}
\hat{H}=\sum_{i=1}^{N} \left(  -\frac{1}{2} \nabla_i^2 + \frac{1}{2} \omega^2r_i^2  \right)+\sum_{i<j}^{N}\frac{1}{r_{ij}},
\end{equation}
$N$ here is number of electrons, $\omega$ is oscillator frequency and $r_{ij}$ distance between two electrons. The first sum here corresponds to the harmonic oscillator and second sum corresponds to the interaction part. The Hamiltonian can be rewritten as
\begin{equation}
\hat{H}=\hat{H}_0+\hat{H}_I .
\end{equation}
%here $\hat{H}_0$ is a standard H.O. part and $\hat{H}_I$ gives a repulsive interaction part. 
%For the Hartree-Fock method we need a single-particle basis, which in this case is just a H.O. functions. However we also need to compute elements for the Coulomb interaction matrix. The details are discussed below in a method description part. 
More detailed the Hamiltonian can be written as 
\begin{equation}
\hat{H} = \sum_{i=1}^{N}\hat{h}_0(i) + \sum_{i < j}^{N}\hat{w}(i,j),
\label{H1H2}
\end{equation}
here $ \hat{h}_0(i) $ represents the kinetic energy of the particle, possibly an external potential and the $\hat{w}(i,j)$ term represents the potential energy of Coulomb interaction between two particles. 

\subsection{Second quantization}
The second quantization is a framework that allows us to write long and cumbersome expressions, such as Slater Determinants and many-body Hamiltonian, in a compact way. This is achived by the usage of so-called creation and annihilation operators.
\cite{umrigarObservationsVariationalProjector2015}
\begin{defn} Creation operator. \\
	We define creation operator as follows:
	\begin{equation}
	c_i^\dagger\ket{-}=\ket{i},
	\end{equation}
	where $\ket{-}$ is a true vacuum state.\\
	Creation operator acting on an arbitrary state of some system results into the following expression:
	\begin{equation}
	c_i^\dagger\ket{p_1 p_2  \dots p_N}=\ket{i p_1p_2 \dots p_N}	
	\end{equation}
\end{defn}
\begin{defn}
	Annihilation operator is defined as hermitian adjoint to creation operator. \\
		\begin{equation}
		c_i\ket{i}=\ket{-}	
		\end{equation}
\end{defn}
Some important results following from the definition of the operators:
\begin{enumerate}
\item $c_i \ket{-}=0$ (no particles).
\item $c_i^\dagger\ket{p_1 p_2  \dots p_N}=0$ if $i=p_i$ (particle already exists in state vector).
\item $c_i\ket{p_1 p_2  \dots p_N}=0$ if $i\neq p_i$ (particle does not exist in state vector).
\end{enumerate}
\section{Operator representation in second quantized form} \label{sec:operator in 2q}
The Hamiltonian now considered in form ($\ref{H1H2}$). Omitting the summations and presenting operators in more generic way, it can be written as:
\begin{equation}
\hat{H}=\hat{H}_0+\hat{W}
\end{equation}
where $\hat{H}_0$ is the so-called one-body term and $\hat{W}$ is the two-body term.
In a second quantized form the one-body term can be written as:
\begin{equation}
\hat{H}_0 = \sum_i^N\hat{h}(i)=\sum_{pq}^{N}\bra{p}\hat{h}\ket{q}c_p^\dagger c_q=\sum_{pq}h_{pq}c_p^\dagger c_q, \\ \label{eq:H0}
\end{equation}
where
\begin{equation}
h_{pq}=\int_{-\infty}^{\infty}\phi_p(x)^* \hat{h}\phi_q(x) dx.\\
\end{equation}
Similarly, the two-body term can be expressed as follows:
\begin{equation}
\hat{W}=\sum_{i<j}^{N} \hat{w}(i,j)=\frac{1}{2}\sum_{pqrs}^{N} w_{rs}^{pq}c_p^\dagger c_q^\dagger c_sc_r\\ \label{eq:W},
\end{equation}
where
\begin{equation}
w_{rs}^{pq}=\bra{pq}\hat{w}\ket{rs}=\int dx_1 \int dx_2 \phi_p(x_1)^*\phi_p(x_2)^* \hat{h}\phi_r(x_1)\phi_s(x_2). 
\end{equation}
As soon as we study fermions it's more convenient to write the two-body term in an antisymmetric form:
\begin{gather}\label{eq:two-body_2q}
	\hat{W}=\frac{1}{4}\sum_{pqrs} \bra{pq}\hat{w}\ket{rs}_{AS} c_p^\dagger c_q^\dagger c_sc_r,
\end{gather}
where
\begin{gather}
	\bra{pq}\hat{w}\ket{rs}_{AS}\equiv \bra{pq}\hat{w}\ket{rs}-\bra{pq}\hat{w}\ket{sr}
\end{gather}
From here on we just use antisymmetric form, so subscript \textit{AS} can be omitted.\\
The Hamiltonian in second quantized form can be then written as:
\begin{equation}\label{eq:Ham in 2q}
\hat{H}=\sum_{pq}^{N}\bra{p}\hat{h}\ket{q}c_p^\dagger c_q + \frac{1}{4}\sum_{pqrs} \bra{pq}\hat{w}\ket{rs}_{AS} c_p^\dagger c_q^\dagger c_sc_r
\end{equation}
\section{Normal ordering and Wick's theorem} \label{sec:Wick}
As it has been already mention we need second quantization to write long expressions in a compact way. However, we also need rules to deal with this expression written in a second quantized form to compute for example matrix elements of Hamiltonain matrix. After writing the Hamiltonian in a second quantized form we are able use for this purpose the following anti-commutator relations:
\begin{gather}
\{c_p,c_q \}=0\\
\{c_p^\dagger,c_q^\dagger \}=0\\
\{c_p,c_q^\dagger\} = \delta_{pq} \label{eq:fund_anti}
\end{gather}
Equation (\ref{eq:fund_anti})  is a fundamental anti-commutator relation. At the same time when the number of particles growing larger this might become too hard to compute even after all simplification have been done so far. There is an easier way to compute matrix elements. To present it we have to introduce some concepts first.
\begin{defn} Vacuum expectation value. \\
	For some arbitrary operator $\hat{O}$ written as string of operators $C_1 \dots C_N$, such that $C_i \in \{c_p^\dagger\} \cup \{c_p\} $ is defined as follows: $ \braket{-|\hat{O}|-}=\bra{-}C_1C_2 \dots C_N \ket{-}$.
\end{defn}
Using the definition above, matrix elements can be obtained by the following expression:
\begin{equation} \label{eq:matrix_elemH0}
\bra{\Phi}\hat{H}_0\ket{\Phi}=\sum_{pq}\bra{p}\hat{h}\ket{q}\bra{-}c_N \dots c_1 c_p^\dagger c_q c_1^\dagger \dots c_N^\dagger \ket{-},
\end{equation}
and
\begin{equation} \label{eq:matrix_elemW}
\bra{\Phi}\hat{W}\ket{\Phi}= \frac{1}{4}\sum_{pqrs} \bra{pq}\hat{w}\ket{rs} \bra{-}c_N \dots c_1 c_p^\dagger c_q^\dagger c_s c_r c_1^\dagger \dots c_N^\dagger \ket{-}. 
\end{equation} 
As one can see from (\ref{eq:matrix_elemH0}) and (\ref{eq:matrix_elemW}) matrix elements are written in form of vacuum expectation value. After this we introduce Wick's Theorem, which allows us to compute these values using normal ordered operators. 
\begin{defn} Normal ordering.\\
	Let $\bar{C}=C_1 \dots C_n$ be an arbitrary operator string consisting of creation and annihilation operators. 
	Let $\sigma \in S_n$ be a permutation, that results in all the creation operators in the string $\bar{C}$ be on the left side and all the annihilation operators to the right side. Normal ordered string denoted using the braces as $\{C_1 \dots C_n \}$. Normal ordering is defined as:
\begin{equation}
	\{C_1 \dots C_n \} \equiv (-1)^{\mid \sigma \mid}[\text{creation operators} ] \times [ \text{annihilation operators}]
\end{equation}
\end{defn}
One should remember that normal order is not a unique sequence of operators, since it is possible to arrange them in a different ways.\\
Another important concept we need to mention before we can go to the Wick's theorem is contraction between operators.

\begin{defn} Contraction.\\
	Contraction between two operators is a difference between their current order and a normal order:
	\begin{equation}
	\wick{\c1 X \c1 Y}= XY - \{XY\}.
	\end{equation}
For creation and annihilation operators one may write four different possible contractions:
\begin{align}
\wick{\c1 c_p \c1 c_q} &=  c_p c_q -  \{c_p c_q\}=0,\\
\wick{\c1 c_p^\dagger \c1 c_q^\dagger}&=  c_p^\dagger c_q^\dagger -  \{c_p^\dagger c_q^\dagger\}=0,\\
\wick{\c1 c_p^\dagger \c1 c_q}&=  c_p^\dagger c_q-  \{c_p^\dagger c_q\}=0,\\
\wick{\c1 c_p \c1 c_q^\dagger}&=  c_p c_q^\dagger -  \{c_p c_q^\dagger\}=\delta_{pq}.
\end{align}
As one can see the only possible non zero contraction is the last one as it correspond to the anti-commutator relation (\ref{eq:fund_anti}) above.
\end{defn}
Below the contraction inside a normal ordered string is defined.
\begin{defn} Contraction inside the operator string.\\
	Let $ \bar{C}=C_1 \dots C_n $ be an arbitrary operator string consisting of creation and annihilation operators. Let $(C_q, C_p)$ be a pair of operators and $\sigma$ be any possible permutation that places $C_q$ to the first place in the string and
	 $C_p$ to the second.
\begin{equation}
	\wick{\{ C_1 \dots \c1 C_q  \dots \c1 C_p \dots C_n \} } \equiv (-1)^{\mid \sigma \mid} \wick{ \{  \c1 C_q  \c1 C_p C_{\sigma(3)} \dots C_{\sigma(n)} \} }.
\end{equation}
	
	For an arbitrary $m$ contractions inside one string we have:
\begin{equation}
	\overbrace{ \{ C_1 \dots C_n\} }^\text{m contractions}=(-1)^{\mid \sigma \mid} 
	\wick{\{ \c1 C_{p_1} \c1 C_{q_1} \dots \c2 C_{p_m} \c2 C_{q_m} C_{\sigma(2m+1)}\dots C_{\sigma(n)}  \} }.
\end{equation}
\end{defn}
Now we can finally state the Wick's theorem.
\begin{theorem}  Wick's theorem.\\
Any operator string can that contains creation and annihilation operators can be also written as sum of a normal ordered product of these operators and all possible contractions inside this normal ordered product.\\
Let $ \bar{C}=C_1 \dots C_n $ be an arbitrary operator string consisting of creation and annihilation operators.
\begin{gather}
C_1 \dots C_n=\{C_1 \dots C_n\} + \sum_{\text{all single contractins}} \overbrace{ \{ C_1 \dots C_n\} }^\text{one contraction} +\\ \sum_{\text{all double contractins}} \overbrace{ \{ C_1 \dots C_n\} }^\text{two contraction}+ \dots + 
 \sum_{\text{all $\frac{n}{2}$ contractins}} \overbrace{ \{ C_1 \dots C_n\} }^\text{$\frac{n}{2}$ contraction}.
\end{gather}
\end{theorem}
Outcomes from Wick's theorem:
\begin{enumerate}
	\item \[\bra{-} \{C_1 \dots C_n\} \ket{-}=0.\]
	\item \[\bra{-} C_1 \dots C_n \ket{-}=0,  \forall  \text{ odd } n.\]
	\item \[\bra{-} C_1 \dots C_n \ket{-}= \sum_{\frac{n}{2}} \overbrace{ \{C_1 \dots C_n\}}^{\text{all contraction}}, \forall \text{ even } n .\]
\end{enumerate}
For the derivation of the coupled cluster equations we need to consider a product of normal-ordered strings. To do this efficiently we also state a generalized Wick's theorem.
\begin{theorem} Generalized Wick's theorem.\\
The generalized Wick's theorem extends the ordinary Wick's theorem for the case of multiple products of normal ordered strings. In this case the only valid contractions are those between the different strings.\\
Let's consider a set of operator strings. $C^1_1 ...C^1_i$, $C^2_1 ...C^2_j$ and $C^n_1 ...C^n_k$. Here $n$ is total number of strings. Then if we need to evaluate the following product of a set of normal-ordered strings:

\begin{align}
\{C_1^1 \dots C_i^1\}\{C_1^2 \dots C_j^2\} ... \{C_1^n \dots C_k^n\} = \{C_1^1 \dots C_i^1|C_1^2 \dots C_j^2| ...| C_1^n \dots C_k^n\} + \nonumber \\
\sum_{\text{all single contractins}} \overbrace{ \{C_1^1 \dots C_k^n\}= \{C_1^1 \dots C_i^1|C_1^2 \dots C_j^2| ...| C_1^n \dots C_k^n\} }^\text{one contraction between strings} + \nonumber \\ \sum_{\text{all double contractins}} \overbrace{ \{C_1^1 \dots C_k^n\}= \{C_1^1 \dots C_i^1|C_1^2 \dots C_j^2| ...| C_1^n \dots C_k^n\} }^\text{two contractions between strings}+\nonumber \\ \dots + 
\sum_{\text{all $\frac{n}{2}$ contractins}} \overbrace{ \{C_1^1 \dots C_k^n\}= \{C_1^1 \dots C_i^1|C_1^2 \dots C_j^2| ...| C_1^n \dots C_k^n\} }^\text{$\frac{n}{2}$ contractions  between strings},
\end{align}
where \textit{contractions between strings} mean we are only considering contractions of the a following type:
	\begin{align}
	\wick{\{\c1 C_1^1 \dots C_i^1|\c1 C_1^2 \dots C_j^2| ...| C_1^n \dots C_k^n\}},\\
	\wick{\{\c1 C_1^1 \dots  C_i^1|  C_1^2 \dots C_j^2|\c1 ... \c2... | C_1^n \c2 \dots C_k^n\}},\\
	\wick{\{\c1 C_1^1 \dots \c3 C_i^1|   C_1^2 ..\c3. C_j^2|\c1 .. \c2. | C_1^n \c2 \dots C_k^n\}},
	\end{align}
	and so on. 
\end{theorem}




 
\section{Normal-Ordered Electronic Hamiltonian}
In section $\ref{sec:operator in 2q}$ we have presented the operator representation in the second quantized form. Equation ($\ref{eq:Ham in 2q}$) that provides the second quantized form of the electronic Hamiltonian can be rewritten using Wick's theorem as the normal ordered operator string. This is a very convenient approach for the derivation of the coupled cluster equations that are provided in Chapter $\ref{ch:coupled_cluster}$.  \\
Let's start with the one-electron part given by equation ($\ref{eq:H0}$):
\begin{equation}
\hat{H_0}=\sum_{pq} \braket{p|\hat{h}|q} \{c_p^\dagger c_q \} + \sum_{i}\braket{i|\hat{h}|i} =\sum_{pq} h_{pq} \{c_p^\dagger c_q \} + \sum_{i}h_{ii}
\end{equation}
Second term in the Hamiltonian equation is the two-body part given by ($\ref{eq:two-body_2q}$). One can rewrite it using Wick's theorem as follows:
\begin{eqnarray}\label{eq::normal1}
c_p^\dagger c_q^\dagger c_s c_r= \{ c_p^\dagger c_q^\dagger c_s c_r  \} + \wick{\{ \c1 c_p^\dagger c_q^\dagger \c1 c_s c_r \}} + \wick{\{  c_p^\dagger \c1 c_q^\dagger \c1 c_s c_r \}} +\nonumber\\  \wick{\{  \c1 c_p^\dagger  c_q^\dagger  c_s \c1 c_r \}} 
+ \wick{\{  c_p^\dagger \c1 c_q^\dagger  c_s \c1 c_r \}} +\wick{\{\c1  c_p^\dagger \c2 c_q^\dagger \c1 c_s \c2 c_r \}} +\wick{\{\c1  c_p^\dagger \c2 c_q^\dagger \c2 c_s \c1 c_r \}}  
\end{eqnarray}
Remembering that the contraction is non-zero only for the operator acting on hole state to the left, we may rewrite ($\ref{eq::normal1} $) as:

\begin{eqnarray}
 \{ c_p^\dagger c_q^\dagger c_s c_r  \} -\delta_{p \in i} \delta_{ps} \{  c_q^\dagger  c_r  \} +\delta_{q \in i} \delta_{qs}  \{  c_p^\dagger  c_r  \} + \delta_{p \in i} \delta_{pr} \{  c_q^\dagger  c_s  \}-\nonumber\\ \delta_{q \in i} \delta_{qr} \{  c_p^\dagger  c_s  \}-  \delta_{p \in i} \delta_{ps} \delta_{q \in j} \delta_{qr}+ \delta_{p \in i} \delta_{pr} \delta_{q \in j} \delta_{qs}
\end{eqnarray}
where $q \in j$ (index $q$ belongs to occupied state) and  $\delta_{q \in j}$ (equality $q=j$ must hold). After this we may rewrite the two-body term in the Hamiltonian and obtain:
\begin{eqnarray}
\frac{1}{4}\sum_{pqrs}\braket{pq|rs}\{ c_p^\dagger c_q^\dagger c_s c_r  \}-\frac{1}{4}\sum_{qri}\braket{iq|ri}\{ c_q^\dagger  c_r  \} +\frac{1}{4}\sum_{pri}\braket{pi|ri}\{ c_p^\dagger  c_r  \} + \nonumber\\ 
+\frac{1}{4}\sum_{qsi}\braket{iq|is}\{ c_q^\dagger  c_s  \} -\frac{1}{4}\sum_{psi}\braket{pi|is}\{ c_p^\dagger  c_s  \} -\frac{1}{4}\sum_{ij}\braket{ij|ij} + \frac{1}{4}\sum_{ij}\braket{ij|ji}  \nonumber\\ 
=\frac{1}{4}\sum_{pqrs}\braket{pq|rs}\{ c_p^\dagger c_q^\dagger c_s c_r  \} + \sum_{pri}\braket{pi|ri}\{ c_p^\dagger  c_r  \} + \frac{1}{2} \sum_{ij}\braket{ij|ij}.
\end{eqnarray}
And finally the Hamiltonian ($\ref{eq:Ham in 2q}$) can be re-written as follows:
\begin{eqnarray}
\hat{H} = \sum_{pq} h_{pq} \{c_p^\dagger c_q \} + \sum_{i}h_{ii} + \frac{1}{4}\sum_{pqrs}\braket{pq|rs}\{ c_p^\dagger c_q^\dagger c_s c_r  \} + \sum_{pri}\braket{pi|ri}\{ c_p^\dagger  c_r  \} + \nonumber\\ \frac{1}{2} \sum_{ij}\braket{ij|ij} 
=  \sum_{pq} f_{pq} \{c_p^\dagger c_q \} + \frac{1}{4}\sum_{pqrs}\braket{pq|rs}\{ c_p^\dagger c_q^\dagger c_s c_r  \} + \braket{\Phi_0|H|\Phi_0},
\end{eqnarray}
with
\begin{equation}\label{eq:Fock_operator}
F_\text{N} = \sum_{pq}f_{pq}\{c_p^\dagger c_q \}=\sum_{pq}\big(h_{pq}\{c_p^\dagger c_q \}+\sum_{i}\braket{pi|qi}\{c_p^\dagger c_q \}\big).
\end{equation}
$F_\text{N} $ is the normal-ordered Fock operator. It is discussed in more detailed manner in Chapter $\ref{ch:HF}$.\\
After this the normal-ordered Hamiltonian can be written as:
\begin{eqnarray}
\hat{H}_N = \hat{H} - \braket{\Phi_0|H|\Phi_0}
\end{eqnarray}
One may say that the normal-ordered form of the operator is obtained by subtracting the reference expectation value of this operator from the operator itself. In this case $\hat{H}_N$ may be referred to as correlation operator.








% and its expectation value is a correlation energy.


\section{Matrix Elements of Hamiltonian}
It is convenient to introduce formulas for different matrix elements of Hamiltonian. We are going to use them lately. \\
!!!!PERENESTI POTOM V DRUGOE MESTO!!!!!!!!!1
Matrix elements between determinants that differs more then two orthonormal spin orbitals are zero by construction, so we are not going to consider such term.\\
Let us choose one determinant to be single or double excitation on another. \\
For double excitation:
\begin{equation}
\ket{\Phi_{m}}=a^\dagger_r a^\dagger_s a_q a_p \ket{\Phi_n}.
\end{equation}
In this case the corresponding matrix element then is:
\begin{equation}
\bra{\Phi_n} \hat{H}\ket{\Phi_{m}}=\braket{rs|pq}_{AS}.
\end{equation}
For single excitation:
\begin{equation}
\ket{\Phi_{m}}=a^\dagger_r  a_p \ket{\Phi_n}.
\end{equation}
And corresponding matrix element then is:
\begin{equation}
\bra{\Phi_n} \hat{H}\ket{\Phi_{m}}=\sum_{k}^{N-1}\braket{rk|pk}_{AS}.
\end{equation}
here sum runs over all common orbitals present in the determinants.\\
We also need to compute the diagonal matrix element:
\begin{equation}
\bra{\Phi_n} \hat{H}\ket{\Phi_{n}}=\sum_{p\in n} \braket{p|\hat{h}|p} + \frac{1}{2} \sum_{p,q \in n}^{N-1}\braket{pq|pq}_{AS}.
\end{equation}

\section{Particle-Hole representation}
In this section we are presenting formalism that is used in many articles and text books on the topic.\\

\begin{defn}Fermi vacuum.\\
	Let $\ket{\Phi_0}$ be n-electron reference determinant constructed using true vacuum $\ket{-}$ and given by:
	\[ \ket{\Phi_0} = c^\dagger_i c^\dagger_j ..\ket{-}. \]
	Such reference determinant is often called a "Fermi vacuum".
\end{defn}

Slater Determinant discussed above is composed using so-called \textit{occupied orbitals}. However they are chosen from a set of single-particle functions that contains also some extra functions. This additional functions are called \textit{virtual orbitals}. There is a convention regarding how to label this occupied and virtual orbitals. It may seen a bit odd, but for occupied orbitals we use name "hole states" and for virtual orbitals we use "particle states". Hole states are labeled with letters \textit{i,j,k} and particle states are labeled with letters \textit{a,b,c}.\\


%Any system of many particles can by described as a reference determinant.
\chapter{Quantum Dot}

\section{Introduction to Quantum Dots}
In this part we provide a theoretical description of 2-dimensional quantum dots. However it's worth talking about what are quantum dots and why are they so interesting before deriving equations. \textit{QDs are sometimes called artificial atoms, due to the fact that they as real atoms has electrons confined inside.} The most commonly QDs are composed by using elements from periodic table of groups II-VI, III-V and IV-VI. For example, GaAs, InAs, ZnS, CdSe and etc.\\
Today we have many types of QDs, with a large field of application. \textit{It is a growing research area.} History of quantum dots traces back to 1980, when they were first discovered in glass crystals \cite{ekimovaiQuantumSizeEffect1981}. However this discovery doesn't result in immediate blow up of the research on the topic. It took quite a time before Murray et al. \cite{murraySynthesisCharacterizationNearly1993} managed to make a colloidal QD. \\
This chapter has a following structure: in the first part a mathematical description of the system under consideration is given starting with all the assumptions and approximation have been made.\\
PRODUCTION. The synthesis of QDs require very high precision and can be accomplished by means of lithographically pattern structures for etching (REF!), selective erea epitaxy (REF), growth on vicinal substructures (REF), colloidal QD solutions (REF) etc.\\  
USAGE. QDs have many applications. QDs are used in lasers, for solid state lighting, for solar cells and also for biological and medical applications \cite{zhuQuantumDots2013}. 

\subsection{Mathematical description of Quantum Dots}\label{sec:math_qd}
Before we can start derive equations we should make some basic assumptions. The main approximation considers the form of Hamiltonian of the system.\\
\begin{enumerate}
	\item Electrons are confined by  Harmonic Oscillator potential $V(r)=\frac{m\omega^2 r^2}{2}$.
	\item Electrons interact via two-body Coulomb potential  $V(r_{ij})=\frac{1}{r_{ij}}$.
	\item The Hamiltonian is considered to be two-dimensional.
	\item The HO potential is spherically symmetric, giving in parabolic quantum dot.
\end{enumerate}

!!!!!\\
We have already presented the Hamiltonian of such system in Section $\ref{sec:manybody}$ equations $\ref{H1H2}$. The unperturbed Hamiltonian eigenvalue can be presented as :
\begin{eqnarray}
E_0= \sum_{i=1}^{N}\epsilon(i),\\
\epsilon(i)= 1+|m_i|+ 2n_i.
\end{eqnarray}

!!!\\


\begin{table}[h!]
	\caption{Quantum numbers for the single-particle basis using a harmonic oscillator in two dimensions.}
	\label{tab:c}
	\begin{center}
		\begin{tabular}{ccccc}
			\hline
			\multicolumn{1}{c}{ Shell number } & \multicolumn{1}{c}{ $(n, m)$ } & \multicolumn{1}{c}{ Energy } & \multicolumn{1}{c}{ Degeneracy } & \multicolumn{1}{c}{ $N$ } \\
			7            & $(0,-6)$ $(1,-4)$ $(2,-2)$ $(3,0)$  $(2,\ 2)$  $(1,\ 4)$  $(0,\ 6)$ & $7\hbar\omega$ & 14         & 56  \\
			\hline
			6            & $(0,-5)$ $(1,-3)$ $(2,-1)$ $(2,\ 1)$  $(1,\ 3)$  $(0,\ 5)$         & $6\hbar\omega$ & 12         & 42  \\
			\hline
			5            & $(0,-4)$ $(1,-2)$ $(2,0)$ $(1,\ 2)$ $(0,\ 4)$                  & $5\hbar\omega$ & 10          & 30  \\
			\hline
			4            & $(0,-3)$ $(1,-1)$ $(1, 1)$ $(0,\ 3)$                          & $4\hbar\omega$ & 8            & 20  \\
			\hline
			3            & $(0,-2)$ $(1,0)$  $(0,\ 2)$                                    & $3\hbar\omega$ & 6          & 12  \\
			\hline
			2            & $(0,-1)$  $(0,\ 1)$                                             & $2\hbar\omega$ & 4          & 6   \\
			\hline
			1            & $(0,0)$                                                       & $\hbar\omega$  & 2          & 2   \\
			\hline
			
			
			
			
		\end{tabular}
	\end{center}
\end{table}


\chapter{The Hatree-Fock theory}\label{ch:HF}
Here we present a brief overview of the Hatree-Fock (HF) theory. It is  well-known and defined way to study systems of large number of particles. Hartree-Fock method is the simplest and nevertheless rather efficient methods. Initially introduced by Hartree and then improved by Fock it is one of the most popular \textit{ab initio} methods in quantum chemistry.  It is  easy to implement, but has some disadvantages, for example it fail to provide high accuracy. However, more precise methods are often build on the HF results. This makes HF theory a good starting point for anyone who want to tackle a many-body problem. Methods that are using HF as an input are usually referred to as post-Hartree-Fock. Among them are Configuration Interaction (CI) and Coupled Cluster (CC). \\
The main idea of HF theory is to approximate unknown wave function with a single Slater Determinant constructed using a single-particle wave functions representing the occupied states in a system under consideration. 
\section{Introduction to HF}
Here we start with time independent Schr\"{o}dinger equation for the ground state:
\begin{equation}
\hat{H}\ket{\Phi_0}=E_0\ket{\Phi_0}
\end{equation}
In order to derive the HF equations we approximate the ground state wave function with a single SD:
\begin{equation}
\ket{\Phi_0}=\prod_{i=1}^{N}c_i^\dagger\ket{-}=\ket{\phi_0, \dots \phi_N}
\end{equation}
Here $\phi_0, \dots \phi_N$ are single-particle wave functions.

This method uses an approximation to the exact many-body wave function by a Slater determinant of $N$ orthonormal single-particle wave functions. In this case the approximate wave function of the system is given by:
\begin{equation}
\Phi(x_1, x_2,\dots ,x_N,\alpha,\beta,\dots, \sigma)=\frac{1}{\sqrt{N!}}
\left| \begin{array}{ccccc} \psi_{\alpha}(x_1)& \psi_{\alpha}(x_2)& \dots & \dots & \psi_{\alpha}(x_N)\\
\psi_{\beta}(x_1)&\psi_{\beta}(x_2)& \dots & \dots & \psi_{\beta}(x_N)\\  
\dots & \dots & \dots & \dots & \dots \\
\dots & \dots & \dots & \dots & \dots \\
\psi_{\sigma}(x_1)&\psi_{\sigma}(x_2)& \dots & \dots & \psi_{\sigma}(x_N)\end{array} \right|, \label{eq:HartreeFockDet}
\end{equation}
In this equation $\psi(x_i)$ stands for the single electron wave function, $x_i$ stand for the coordinates and spin values of a particle $i$ and $\alpha, \beta,…,\sigma$ are quantum numbers needed to describe remaining quantum numbers.
However this expression can be simplified by introducing a new operator $\hat{A}$. This operator is given by 
\begin{equation}
\hat{A} = \frac{1}{N!}\sum_{p} (-)^p\hat{P},
\label{antiSymmetryOperator}
\end{equation}
here the sum goes over all possible permutations of two particles and $p$  stands for the number of permutations.\\
We also need to introduce Hartree-Fock wave function, which is given by product of all possible single-particle wave functions
\begin{equation}
\Phi_H(x_1,x_2,\dots,x_N,\alpha,\beta,\dots,\nu) =
\psi_{\alpha}(x_1)
\psi_{\beta}(x_2)\dots\psi_{\nu}(x_N).
\end{equation}
Using this notations Slater determinant can be rewritten as
\begin{equation}\label{determ}
\Phi(x_1,x_2,\dots,x_N,\alpha,\beta,\dots,\nu) = \frac{1}{\sqrt{N!}}\sum_{P} (-)^P\hat{P}\psi_{\alpha}(x_1)
\psi_{\beta}(x_2)\dots\psi_{\nu}(x_N)=\sqrt{N!}\hat{A}\Phi_H,
\end{equation}
Using a Slater determinant and assuming the Hamiltonian is given on form (\ref{eq:finalH}) we may obtain the functional $E[\Phi]$ for the energy. According to the variational principle
\begin{equation}
E[\Phi] \ge E_0
\end{equation}
here $E_0$ denote the exact ground state energy. 
There are two main strategies we may use now in order to obtain the ground state energy. In order to find the minimum of the energy functional we may either vary a Slater determinant, or we may expand the single-particle functions in some known basis and then vary the coefficients of expansions. In this project we use the second method. For those who want more detailed insight in the theory presented above in this chapter, please take a look at chapter 15 in \cite{mortenhjorth-jensenCOMPUTATIONALPHYSICS2015}.

\section{Derivation of a Hartree-Fock equations}
In order to derive the Hartree-Fock equations we need to chose an orthogonal basis to be used for expansion. As soon as we have H.O. potential that confine particles in the system it's reasonable to choose H.O. functions as a basis functions for the expansion as well. In this case we can be sure the functions are orthogonal by nature. 
\begin{equation}
\psi_p  = \sum_{\lambda} C_{p\lambda}\phi_{\lambda}. \label{eq:newbasis}
\end{equation}
here $\phi_{\lambda}$ is our new basis functions and $C_{p\lambda}$ represent expansion coefficients. This is a very important property for us, as soon as we will vary the coefficients in order to minimize energy. The sum in (\ref{eq:newbasis}) goes to infinity, however we will use a truncation to a certain value. \\
Using the definitions we introduce in part \ref{not} we may write the energy functional as
\begin{equation}
E[\Phi] 
= \sum_{\mu=1}^N \langle \mu | \hat{h}_0 | \mu \rangle +
\frac{1}{2}\sum_{{\mu}=1}^N\sum_{{\nu}=1}^N \langle \mu\nu|\hat{v}|\mu\nu\rangle_{\mathrm{AS}}.
\label{FunctionalEPhi}
\end{equation}
here $\mu$ and $\nu$ are basis functions we use in Slater determinant $\Phi$ defined in (\ref{determ}). After expansion in a new basis the functional for the energy turns into:
\begin{equation}
E[\Psi] 
= \sum_{i=1}^N \sum_{\alpha\beta}^Z C^*_{i\alpha}C_{i\beta}\langle \alpha | h | \beta \rangle +
\frac{1}{2}\sum_{ij=1}^N\sum_{{\alpha\beta\gamma\delta}}^Z C^*_{i\alpha}C^*_{j\beta}C_{i\gamma}C_{j\delta}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}. \label{FunctionalEPhi3}
\end{equation}
Here $\Psi$ is a new Slater determinant and $\alpha,\beta,\gamma,\delta$ correspond to new basis functions and $Z$ is energy cut-off representing the total possible number of states in a chosen basis. Coefficients $C$ are expansion coefficients from (\ref{eq:newbasis}). They form a unitary matrix that performs a transformation to a new basis and also preserve orthogonality of the basis functions. This allows us to use the Lagrange multiplier method to find the local minimum of the energy functional. We use orthogonality requirement as a constraint and set up a Lagrange functional, were all multipliers have to be in units of energy as soon as matrix $C$ contains only some numbers. Those energies are often called Hartree-Fock single particle energies. They are different from the single-particle energies corresponding to the basis functions because we chose the basis to be H.O. functions without any perturbations. However as it discussed below this new single-particle energies follow the same degeneracy pattern as a pure H.O. energies for the system (below the Fermi level). 
After applying the Lagrange multipliers method we obtain the following expression
\begin{equation}
\sum_{\beta}^Z C_{i\beta}\langle \alpha | h | \beta \rangle+
\sum_{j=1}^N\sum_{\beta\gamma\delta}^Z C^*_{j\beta}C_{j\delta}C_{i\gamma}\langle \alpha\beta|\hat{v}|\gamma\delta\rangle_{AS}=\epsilon_i^{HF}C_{i\alpha}.
\end{equation}
here $\epsilon_i^{HF}$ are new single-particle energies. Now we define Hartree-Fock matrix as
\begin{equation}
h_{\alpha\beta}^{HF}=\langle \alpha | h | \beta \rangle+
\sum_{j=1}^N\sum_{\gamma\delta} C^*_{j\gamma}C_{j\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS},
\end{equation}
once we obtain a matrix eigenvalue problem:
\begin{equation} \label{eig}
\hat{h}^{HF}\hat{C}=\epsilon^{\mathrm{HF}}\hat{C}.
\end{equation}
To simplify computations in our program we use so called density matrix. It is defined as
\begin{equation} \label{dens}
\rho_{\gamma\delta}=\sum_{i\le F}\langle\gamma|i\rangle\langle i|\delta\rangle = \sum_{i\le F}C_{i\gamma}C^*_{i\delta}.
\end{equation}
In this case Hamiltonian can be rewritten as 
\begin{equation}
\hat{h}_{\alpha\beta}^{HF}=\epsilon_{\alpha}\delta_{\alpha,\beta}+
\sum_{\gamma\delta} \rho_{\gamma\delta}\langle \alpha\gamma|\hat{v}|\beta\delta\rangle_{AS}.
\end{equation}
\section{Hartree-Fock basis}





\chapter{Coupled Cluster method} \label{ch:coupled_cluster}
Coupled cluster (CC) method for quantum chemistry was first introduced by J. Cizek in the late 1960s \cite{cizekCorrelationProblemsAtomic}. A few years later he publish a new article on the topic in collaboration with and J. Paldus \cite{cizekCorrelationProblemAtomic1966}. CC is an \textit{ab initio} numerical method widely used for approximate solution of electronic Schr\"{o}dinger equation because it is both reliable and computationally affordable. This section is based on a very detailed and comprehensive overview of the method provided by Crawford and Schaefer in \cite{crawfordIntroductionCoupledCluster2007}. Coupled cluster method is based on the same basic concepts that are underlying many other many-body methods, such as many-body perturbation theory and full configuration interaction. The main critical difference is use of "exponential ansatz" of the wave function which is discussed below.\\
In this chapter we discuss some critical ideas for the CC, such as cluster expansion of the wave function , exponential ansatz, Campbell-Baker-Hausdorff (BCH) expansion, second quantization and particle-hole formalizm, normal-ordering and correlation operator in application for CC method. Some of this ideas we have already mention in previuos chapter and some are completely new. The CC method can be described in two different ways using algebraic and diagrammatic formalisms. Both are correct and provide same results, but diagrammatic one is a way faster. However, for understanding of the method and it's origin we need to begin with algebraic form of the equations.\\
\section{Cluster functions and Exponential Anzats} 
As we have already discussed above Slater Determinant can be used to describe a wave function of the electrons. In Dirac notations it can be written as follows:
\begin{equation}
\Phi_0 =  \ket{\phi_i(\bm{x_1})\phi_j(\bm{x_2}) ...\phi_l(\bm{x_n})}
\end{equation}
here $\phi_i(\bm{x_1})$ is a one-electron wave function, that describes motion of each electron separately, the $\bm{x_1}$ is a vector of coordinates, both spatial and spin. \\
Keeping in mind that we are working with fermions, electronic wave function should be antisymmetric. \\
Such description has some drawbacks, for example it fails to take into account the instantaneous interactions that keep apart electrons with opposite spins. For more details please refer to  \cite{bartlettApplicationsPostHartree2007} and \cite{ModernQuantumChemistry}. \\
The most important idea of CC method is exponential exopantion of wave function. 
\begin{equation}\label{eq:exponential ansatz}
\ket{\Psi}=e^{\hat{T}}\ket{\Phi_0}.
\end{equation}
Where $\hat{T}$ is cluster operator:

\begin{align} \label{eq:T}
\hat{T}= \hat{T_1}+ \hat{T_2}+ \hat{T_3}...\hat{T_n},  \\
\hat{T_1}= \sum_{i,a} t_i^a c_a^\dagger c_i, \label{eq:T1}\\
\hat{T_2}= \frac{1}{4} \sum_{i,j,a,b} t_{i,j}^{a,b} c_a^\dagger a_b^\dagger c_j c_i,\\
\hat{T_n}= \bigg(\frac{1}{n!}\bigg)^2 \sum_{i,j \dots a,b\dots } t_{i,j\dots}^{a,b\dots}  c_a^\dagger c_b^\dagger \dots c_j c_i.\\
\end{align}
here values $t_i^a $ and $t_{i,j}^{a,b}$ are called cluster amplitudes. \\
After introducing the exponential ansatz we need a reciepe to determine the cluster amplitudes. In order to do this we start with electronic Schr\"{o}dinger equation (REFERENCE!!!) and use equation ($\ref{eq:exponential ansatz}$) to approximate the exact wave function:
\begin{equation}
	\hat{H}e^{\hat{T}}\ket{\Phi_0}=Ee^{\hat{T}}\ket{\Phi_0}.
\end{equation}
Using the \textit{intermediate normalization} $\braket{\Phi_0|\Psi_{CC}}=1$ and  the equation above we can immediately get the energy:
\begin{equation}\label{eq:energy simple cc}
\bra{\Phi_0}\hat{H}e^{\hat{T}}\ket{\Phi_0}=E.
\end{equation}
Now we want to use the fact that exponentiated operator can be expressed in terms of power series:
 \begin{equation}
 e^{\hat{T}}= 1+ \hat{T}+\frac{1}{2!}\hat{T}^2+ ...
 \end{equation}
If we now insert this equation into equation ($\ref{eq:energy simple cc}$) and simplify a bit we obtain:
\begin{equation}
 \bra{\Phi_0}\hat{H}\ket{\Phi_0} +  \bra{\Phi_0}\hat{H}\hat{T}\ket{\Phi_0} +\bra{\Phi_0}\hat{H}\frac{1}{2!}\hat{T}^2\ket{\Phi_0}  = E.
\end{equation}
In the energy equation above the exponential expansion is truncated after $\hat{T}^2$. This fact if often reffed to as \textit{natural truncation} of the coupled cluster energy equation. It's important here that truncation occurs due to the fact that Hamiltonian in our case is at most two-body operator and cluster operator is at least one-body. It this case matrix elements of Hamiltonian are zero for all determinants that differ more then two orbitals. This truncation does not depend on number of particles or any other parameter, it only occurs due to the form of Hamiltonian. \\
The amplitude expressions can be computed using the same projection technique, only instead of projecting into reference we will be projecting into exited determinant. 
\begin{equation}\label{eq:ampl simple}
\bra{\Phi_{ij...}^{ab...}}\hat{H} e^{\hat{T}}\ket{\Phi_0} = E\bra{\Phi_{ij...}^{ab...}} e^{\hat{T}}\ket{\Phi_0}.
\end{equation}
!!!!!!!!!!!!!!!!!!!ADD TEXT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
\subsection{Hausdorff Expansion} \label{sec:Hausdorf}
Expressions for energy and amplitudes in the section above are not useful for practical computations. In order to obtain equations that can be efficiently implemented in computer programs we are going to use so called similarly transformed Hamiltonian. It is a well known procedure in quantum mechanics. 

ADD TEXT ABOUT SIMILARITY TRANSFORMATIONS\\
For energy equation we get:
\begin{equation}\label{eq:energy_cc1}
\bra{\Phi_0} e^{\hat{-T}} \hat{H} e^{\hat{T}} \ket{\Phi_0}   = E. 
\end{equation}
And for amplitudes equation we get:
\begin{equation}\label{eq:amplitudesgeneral}
\bra{\Phi_{ij...}^{ab...}}e^{\hat{-T}} \hat{H} e^{\hat{T}} \ket{\Phi_0}   = 0.
\end{equation} 
These equations are equivalent to ($\ref{eq:ampl simple}$) and ($\ref{eq:energy simple cc}$) derived in the sections above. However there are two significant advantages this transformation provides to the method. Equations for amplitude are now not coupled to the energy equation and we may use so called Hausdorff expansion (or Campbell-Baker-Hausdorff formula) and rewrite the expression for $ e^{\hat{-T}} \hat{H} e^{\hat{T}} $ in terms of linear combinations of nested commutators of $ \hat{H} $ and $\hat{T}$.
\begin{equation}
e^{\hat{-T}} \hat{H} e^{\hat{T}} = \hat{H} + [\hat{H},\hat{T}] + \frac{1}{2!}[[\hat{H},\hat{T}],\hat{T}] + \frac{1}{3!}[[[\hat{H},\hat{T}],\hat{T}],\hat{T}] + ...
\end{equation} 
Here we need to make a very important remark regarding the transformation we have done. As it has been mentioned in chapter one quantum mechanics demand that observables are expectation values of hermitian operators (Postulate $\ref{postulat2}$). The operator  $e^{\hat{-T}} \hat{H} e^{\hat{T}} $ is obviously not hermitian. 
\begin{equation}
(e^{\hat{-T}} \hat{H} e^{\hat{T}})^\dagger \neq e^{\hat{-T}} \hat{H} e^{\hat{T}}
\end{equation} 
However, the eigenvalue spectrum of this operator is identical to the original Hamiltonian operator. For details please refer to \cite{kutzelniggAlmostVariationalCoupled}.

\section{Coupled Cluster Equations}
\subsection{Energy Equation}
In previous section $\ref{sec:Hausdorf}$ we have introduced Hausdorff expansion for similarly transformed Hamiltonian. Now we will use it to derive energy equation. In case of CCSD (meaning $\hat{T}=\hat{T}_1+\hat{T}_2$) the similarly transformed normal ordered Hamiltonian $\bar{H}=e^{\hat{-T}} \hat{H}_\text{N} e^{\hat{T}}$ can be written as:

\begin{eqnarray}\label{eq:hausdorf_ccsd}
 \hat{H}_\text{N} + [\hat{H}_\text{N},\hat{T}_1+\hat{T}_2] + \frac{1}{2!}[[\hat{H}_\text{N},\hat{T}_1+\hat{T}_2],\hat{T}_1+\hat{T}_2] + ...= \nonumber\\
 \hat{H}_\text{N} + [\hat{H}_\text{N},\hat{T}_1] + [\hat{H}_\text{N},\hat{T}_2] + \frac{1}{2}[[\hat{H}_\text{N},\hat{T}_1],\hat{T}_1] +\nonumber\\ \frac{1}{2}[[\hat{H}_\text{N},\hat{T}_2],\hat{T}_2] +  \frac{1}{2}[[\hat{H}_\text{N},\hat{T}_1],\hat{T}_2] + \frac{1}{2}[[\hat{H}_\text{N},\hat{T}_2],\hat{T}_1] + ...
\end{eqnarray}

We now want to insert ($\ref{eq:hausdorf_ccsd}$) into ($\ref{eq:energy_cc1}$). The $\hat{H}_\text{N}$ term is trivial as $\braket{\Phi_0|\hat{H}_\text{N}|\Phi_0}=0$.\\
Next term is a bit more interesting:
\begin{eqnarray}\label{eq:firstterm}
 [\hat{H}_\text{N},\hat{T}_1] =  [\hat{F}_\text{N},\hat{T}_1] +  [\hat{V}_\text{N},\hat{T}_1].
\end{eqnarray}
Using ($\ref{eq:T1}$) and the formulation of Fock operator from ($\ref{eq:Fock_operator}$) we need to deal with products of operator strings and we may immediately re-write them using Wick's theorem:
\begin{eqnarray}
\{c_p^\dagger c_q \}\{c_a^\dagger c_i \} =\{c_p^\dagger c_q c_a^\dagger c_i \} + \wick{ \{\c1 c_p^\dagger c_q c_a^\dagger \c1 c_i \} } + \wick{ \{ c_p^\dagger \c1 c_q \c1 c_a^\dagger  c_i \} } +
 \wick{ \{ \c2 c_p^\dagger \c1 c_q \c1 c_a^\dagger \c2  c_i \} } = \nonumber\\
 \{c_p^\dagger c_q c_a^\dagger c_i \} + \delta_{pi} \{ c_q c_a^\dagger\} +\delta_{qa} \{  c_p^\dagger c_i \} +  \delta_{pi}\delta_{qa}\\
 \{c_a^\dagger c_i \}\{c_p^\dagger c_q \}= \{c_p^\dagger c_q c_a^\dagger c_i \}.
\end{eqnarray}
Using this the next term ($\ref{eq:firstterm}$) in expansion ($\ref{eq:hausdorf_ccsd}$) may be written as and the fact that expectation value of normal ordered operator string is zero by contraction (only fully contracted terms make contribution to the energy) we get:
\begin{eqnarray}
\bra{\Phi_0}[\hat{F}_\text{N},\hat{T}_1] \ket{\Phi_0}=\sum_{ia} f_{ia}t_i^a,\\
\bra{\Phi_0}[\hat{V}_\text{N},\hat{T}_1] \ket{\Phi_0}=0.
\end{eqnarray}
Next term is:
\begin{eqnarray}\label{eq:secondterm}
[\hat{H}_\text{N},\hat{T}_2]=[\hat{F}_\text{N},\hat{T}_2] +  [\hat{V}_\text{N},\hat{T}_2].
\end{eqnarray} 
Following the same procedure as before we get:
\begin{eqnarray}
\bra{\Phi_0}[\hat{F}_\text{N},\hat{T}_2] \ket{\Phi_0}=0\\
\bra{\Phi_0}[\hat{V}_\text{N},\hat{T}_2] \ket{\Phi_0}=\frac{1}{4}\sum_{ijab}\braket{ij|\hat{v}|ab}t_{ij}^{ab}
\end{eqnarray}
And for the next term we have:
\begin{eqnarray}
\frac{1}{2}[[\hat{H}_\text{N},\hat{T}_1],\hat{T}_1]= \frac{1}{2}\hat{H}_\text{N}\hat{T}_1^2 -\hat{T}_1\hat{H}_\text{N}\hat{T}_1 + \frac{1}{2}\hat{T}_1^2\hat{H}_\text{N}=\nonumber \\
 \frac{1}{2}\hat{F}_\text{N}\hat{T}_1^2 +  \frac{1}{2}\hat{V}_\text{N}\hat{T}_1^2 
 -\hat{T}_1\hat{F}_\text{N}\hat{T}_1  -\hat{T}_1\hat{V}_\text{N}\hat{T}_1 + 
 \frac{1}{2}\hat{T}_1^2\hat{F}_\text{N} +  \frac{1}{2}\hat{T}_1^2\hat{V}_\text{N}
\end{eqnarray}
Let us consider this one more carefully, because it can help us to state a so-called connected contraction theorem.
\begin{eqnarray}
\hat{F}_\text{N}\hat{T}_1^2 = \sum_{ijab} \sum_{pq}f_{pq}t_i^at_j^b(\{c_p^\dagger c_q c_a^\dagger c_i c_b^\dagger c_j \}+ \wick{\{\c1 c_p^\dagger c_q c_a^\dagger \c1 c_i c_b^\dagger c_j \}}  +\wick{\{\c1 c_p^\dagger c_q c_a^\dagger  c_i c_b^\dagger \c1c_j \}} + \nonumber \\
\wick{\{ c_p^\dagger \c1 c_q \c1c_a^\dagger  c_i c_b^\dagger c_j \}} + \wick{\{ c_p^\dagger \c1 c_q c_a^\dagger  c_i \c1 c_b^\dagger c_j \}} + \wick{\{ \c2 c_p^\dagger  \c1 c_q \c1 c_a^\dagger \c2 c_i  c_b^\dagger  c_j \}} + \nonumber \\ \wick{\{ \c2 c_p^\dagger  \c1 c_q \c1 c_a^\dagger  c_i  c_b^\dagger \c2 c_j \}}+ \wick{\{ \c2 c_p^\dagger  \c1 c_q  c_a^\dagger \c2 c_i \c1 c_b^\dagger  c_j \}}+  \wick{\{ \c2 c_p^\dagger  \c1 c_q  c_a^\dagger  c_i \c1 c_b^\dagger \c2 c_j \}})
\end{eqnarray}
As we can see there is no fully contracted terms in the expression above. Two other terms can be written as:
\begin{align*}
\hat{T}_1\hat{F}_\text{N}\hat{T}_1= \sum_{ijab} t_i^at_j^b \bigg( \sum_{pq}f_{pq} \{c_a^\dagger c_ic_p^\dagger c_q  c_b^\dagger c_j \} +  \sum_{q}f_{jq}\{c_a^\dagger c_i  c_q  c_b^\dagger \} +  \sum_{p}f_{pb}\{c_a^\dagger c_i   c_p^\dagger c_j \} + f_{jb}\{c_a^\dagger c_i \}\bigg)\nonumber \\
\hat{T}_1^2\hat{F}_\text{N} =\sum_{ijab}  \sum_{pq}f_{pq}  t_i^at_j^b \{c_a^\dagger c_ic_b^\dagger c_j  c_p^\dagger c_q   \} \nonumber \\
\end{align*}
Non of the above contribute to the energy expectation value. However the term $[\hat{F}_\text{N},\hat{T}_1] $ does. Using this to facts we may now formulate the connected contraction theorem:
\begin{theorem} Connected Cluster Theorem \\ \label{theo:connected}
The contribution to the energy expectation value from the terms in Hausdorff expansion of similarly transformed normal ordered Hamiltonian is non zero only if the the $\hat{H}_\text{N}$ has at least one contraction with every cluster operator on the right side.\\
Such connected contraction is denoted with subscript $(...)_c$.
\end{theorem}
Using this theorem one can say that as soon as Hamiltonian has at most four operators the Hausdorff expansion can have at most four cluster operators. This eventually makes the derivation of energy and amplitudes equations much easier.\\
Let's continue on derivation of energy equation using the connected contractions. Contribution from $(\hat{F}_\text{N}\hat{T_2})_c$ is zero by construction, due to absence of fully contracted terms ($\hat{F}_\text{N}$ contains two operators and $\hat{T_2}$ has four). The contribution from $(\hat{V}_\text{N}\hat{T_2})_c$ is non zero, because we have two normal ordered operator strings of the same size here.:
\begin{equation}
\bra{\Phi_0}(\hat{V}_\text{N}\hat{T}_2)_c \ket{\Phi_0}=\frac{1}{4}\sum_{ijab} \braket{ij||ab}t_{ij}^{ab}.
\end{equation}
Next non-zero contribution comes from term $(\hat{V}_\text{N}\hat{T_1}^2)_c$:
\begin{equation}
\bra{\Phi_0}(\hat{V}_\text{N}\hat{T}_1^2)_c \ket{\Phi_0}=\sum_{ijab} \braket{ij||ab}t_{i}^{a}t_{j}^{b}.
\end{equation}
Gathering all the term carefully one obtain the following expression for the correlation energy:
\begin{equation}
E_{corr}= E_{CCSD} - E_{HF}= \sum_{ia} f_{ia}t_i^a + \frac{1}{4}\sum_{ijab} \braket{ij||ab}t_{ij}^{ab} +\frac{1}{2}\sum_{ijab} \braket{ij||ab}t_{i}^{a}t_{j}^{b}.
\end{equation}
Or in case of coupled clusters doubles simply:
\begin{equation}
E_{corr}= E_{CCD} - E_{HF}= \frac{1}{4}\sum_{ijab} \braket{ij||ab}t_{ij}^{ab}.
\end{equation}
\subsection{Amplitudes equations}
Above we presented a general form for amplitudes equation in ($\ref{eq:amplitudesgeneral}$). Depending on the truncation of cluster operator we may have different types of coupled cluster methods: coupled cluster singles and doubles (CCSD), coupled cluster doubles (CCD) or coupled cluster singes, doubles and triples (CCSDT). The general form for amplitude equations ($\ref{eq:amplitudesgeneral}$) then can be used to find singly-excited amplitudes $t_{i}^{a}$ and doubly-excited amplitudes  $t_{ij}^{ab}$. 


\begin{eqnarray}
\bra{\Phi_{ij}^{ab}}e^{\hat{-T}} \hat{H} e^{\hat{T}} \ket{\Phi_0}   = 0 \xRightarrow{~\textsf{CCD}~} \text{ for  $t_{ij}^{ab}$}
\end{eqnarray}

\begin{eqnarray}
\begin{aligned}
\bra{\Phi_{i}^{a}}e^{\hat{-T}} \hat{H} e^{\hat{T}} \ket{\Phi_0}   = 0  \\
\bra{\Phi_{ij}^{ab}}e^{\hat{-T}} \hat{H} e^{\hat{T}} \ket{\Phi_0}   = 0  \end{aligned}
\xRightarrow{~\textsf{CCSD}~}
\begin{aligned}
\text{ for  $t_{i}^{a}$} \\
\text{ for  $t_{ij}^{ab}$} \end{aligned}
\end{eqnarray}

\begin{eqnarray}
\begin{aligned}
\bra{\Phi_{i}^{a}}e^{\hat{-T}} \hat{H} e^{\hat{T}} \ket{\Phi_0}   = 0  \\
\bra{\Phi_{ij}^{ab}}e^{\hat{-T}} \hat{H} e^{\hat{T}} \ket{\Phi_0}   = 0 \\
\bra{\Phi_{ijk}^{abc}}e^{\hat{-T}} \hat{H} e^{\hat{T}} \ket{\Phi_0}   = 0  \\ \end{aligned}
\xRightarrow{~\textsf{CCSDT}~}
\begin{aligned}
\text{ for  $t_{i}^{a}$} \\
\text{ for  $t_{ij}^{ab}$} \\
\text{ for  $t_{ijk}^{abc}$} \end{aligned}
\end{eqnarray}
And so on.\\
Equations for amplitudes are derived using same approach as for the energy, we just write all operators as normal ordered strings and look for fully contracted and connected clusters. Additionally we need to write an excited determinant as an operator string also:
\begin{eqnarray}
\bra{\Phi_{ij}^{ab}} = \bra{\Phi_0} \{  c_i^\dagger c_j^\dagger  c_b  c_a \}.
\end{eqnarray}
The derivation is rather simple, though quite time-consuming due to number of terms in BSH expansion to take care of. We are not going to tackle all of them and will just present some as an example.\\
We are going to look into CCD approximation here, thus only consider terms that contribute to the amplitudes for $\hat{T}_2$.\\
The one-body term does not contribute because it is not possible to construct fully contracted terms, so the only term that is able to produce such contractions is:
\begin{eqnarray}
\braket{\Phi_{ij}^{ab}|(\hat{F}_\text{N}+\hat{V}_\text{N})|\Phi_0} \rightarrow \braket{\Phi_{ij}^{ab}|(\hat{V}_\text{N})|\Phi_0},\nonumber \\
\braket{\Phi_{ij}^{ab}|(\hat{V}_\text{N})|\Phi_0} = \frac{1}{4}\sum_{pqrs} \braket{pq||rs}\braket{\Phi_0| \{  c_i^\dagger c_j^\dagger  c_b  c_a \} \{  c_p^\dagger c_q^\dagger  c_s  c_r \} |\Phi_0}=\nonumber \\
 \frac{1}{4}\sum_{pqrs} \braket{pq||rs} \bigg( \wick{ \{ \c4 c_i^\dagger \c3 c_j^\dagger \c2 c_b \c1 c_a \c1  c_p^\dagger \c2 c_q^\dagger \c3 c_s \c4 c_r \}  } 
 + \wick{ \{ \c4 c_i^\dagger \c3 c_j^\dagger \c2 c_b \c1 c_a \c2  c_p^\dagger \c1 c_q^\dagger \c3 c_s \c4 c_r \}  } + \nonumber \\
  \wick{ \{ \c4 c_i^\dagger \c3 c_j^\dagger \c2 c_b \c1 c_a \c1  c_p^\dagger \c2 c_q^\dagger \c4 c_s \c3 c_r \}  }+\wick{ \{ \c4 c_i^\dagger \c3 c_j^\dagger \c2 c_b \c1 c_a \c2  c_p^\dagger \c1 c_q^\dagger \c4 c_s \c3 c_r \}  }  \bigg) =\braket{ab||ij}
\end{eqnarray}
Contribution from other terms are obtained in the similar manner, one just need to kepp in mind that for terms with cluster operator, like $\braket{\Phi_{ij}^{ab}|(\hat{F}_\text{N}\hat{T}_2)_c|\Phi_0}$ and $\braket{\Phi_{ij}^{ab}|(\hat{V}_\text{N}\hat{T}_2)_c|\Phi_0}$ the Connected Cluster Theorem $\ref{theo:connected}$ must be satisfied.\\
The final expression for the amplitudes in case of CCD approximation is the following:
\begin{eqnarray}
0 =\braket{ab||ij} + \sum_{c}(f_{bc}t_{ij}^{ac}-f_{ac}t_{ij}^{bc} ) - \sum_{k}(f_{kj}t_{ik}^{ab}-f_{ki}t_{jk}^{ab} ) + \frac{1}{2} \sum_{kl}\braket{kl||ij}t_{kl}^{ab} \nonumber &+\\
 \frac{1}{2} \sum_{cd}\braket{ab||cd}t_{ij}^{cd} + P(ij)(ab)  \sum_{kc}\braket{kb||cj}t_{ik}^{ac} + 
 \frac{1}{2} P(ij)(ab) \sum_{klcd}\braket{kl||cd}t_{ik}^{ac} t_{lj}^{db} \nonumber & + \\
 \frac{1}{4} \sum_{klcd}\braket{kl||cd}t_{ij}^{cd} t_{kl}^{ab}  
- \frac{1}{2} P(ab) \sum_{klcd}\braket{kl||cd}t_{ij}^{ac} t_{kl}^{bd}- \frac{1}{2} P(ij) \sum_{klcd}\braket{kl||cd}t_{ik}^{ab} t_{jl}^{cd} &  
\end{eqnarray}






\chapter{Monte Carlo Methods in Quantum Physics}
Quantum Monte Carlo(QMC) methods are widely used nowadays for systems with large number of particles. In main distinction of these simulation techniques is in their stochastic nature, which is not the case for other simulation methods, such as molecular dynamics. For more on the topic please refer to \cite{hammondMonteCarloMethods1994} and \cite{kalosMonteCarloMethods2008}. \\
These methods are flexible and at the same time accurate for many-body systems. There are two most common types of QMC, firs is variational Monte Carlo method (VMC) and projector Monte Carlo method (PMC). For PMC methods differ by a form of projector, e.i. exponential or linear. The most common choice is an exponential one also sometimes called as imaginary time propagator.\\
The essence of VMC method is to choose a trial wave function, depending on some parameters and then for this particular trial wave function to find expectation values of operators and optimize the parameters.\\
At the same time PMC methods also use trial wave functions. In general PMC is a stochastic application of power method to compute expectation values for eigenstate corresponding to largest absolute eigenvalue.The main advantage of the PMC methods compared to the common matrix diagonalization algorithms, for example iterative and deterministic Lanczos algorithm, is that for stochastic method we do not need to store the whole vector, but just some randomly sampled elements of the vector \cite{umrigarObservationsVariationalProjector2015}. \\
In this thesis we are implementing a coupled cluster Monte Carlo (CCMC) method which has much in common with one of the PMC methods a diffusion Monte Carlo (DMC) method. In order to simplify the explanation we start with some quick recap on what is DMC.\\
\section{Diffusion Monte Carlo} \label{sec:DMC}
The DMC method employ the imaginary time propagator:
\begin{equation}
\hat{P(\tau)}=e^{\tau(E_T\hat{1}- \hat{H})},
\end{equation}
here $\tau= it$ is imaginary time.\\
This method is called  diffusion one can do a mapping between a classical diffusion equation and an imaginary-time Schr\"{o}dinger equation. Let's consider the following form of  Schr\"{o}dinger equation:
\begin{equation}\label{eq:imaginary_schrod}
		\frac{\partial }{ \partial \tau}\ket{\Psi(\textbf{x},\tau)} = \frac{1}{2} \nabla^2 \ket{\Psi(\textbf{x},\tau)} + (E_T - V(\textbf{x}) \ket{\Psi(\textbf{x},\tau)},
\end{equation}

This equation is very similar to a classical equation:
\begin{equation}\label{eq:diffusion}
\frac{\partial C }{ \partial t} = D \frac{\partial^2 C }{ \partial t^2} - kC,
\end{equation}
here $D$ is diffusion constant, $C$ is concentration of particles and $k$ proportionality coefficient describing source or sink of particles. First part on the right hand side of this equation describe a classical diffusion process and the second part is just a first order rate equation. The meaning of $k$ is the following - particles can be destroyed or created proportional to $k$.\\
If we compare two equations together ($\ref{eq:imaginary_schrod}$) and ($\ref{eq:diffusion}$) they are not really alike, due to imaginary time and a wave function. However similarities between this two allow us to use some techniques normally used for classical simulations to imaginary-time Schr\"{o}dinger equation. Monte Carlo methods are capable to simulate both diffusion and rate, so we can just build up a method that combine this two processes into one.  \\
First we require $\tau \rightarrow \infty $ we obtain time-independent equation. 


First lets consider a kinetic energy term in the equation. 


\section{Stochastic Coupled Cluster Theory}
In chapter $\ref{ch:coupled_cluster}$ we have introduced a coupled cluster method. However, the main problem with exact coupled cluster computations is with system size. Scaling starts with the sixth order of $N$ (here $N$ represents system size) that makes even small systems very costly in computations. Coupled Cluster Monte Carlo (CCMC) is a new method which has been first described by Alex Thom in \cite{thomStochasticCoupledCluster2010}. The method has been developed similarly to Full Configuration Interaction Quantum Monte Carlo (FCIQMC) of Alavi \textit{et al.} in \cite{boothFermionMonteCarlo2009}, \cite{clelandCommunicationsSurvivalFittest2010} and \cite{boothApproachingChemicalAccuracy2010}.\\
In order to explain how we get to CCMC algorithm we first present a brief description of FCIQMC. \\
\subsection{Full Configuration Interaction Quantum Monte Carlo}
The CI wave function is represented by the following expansion:
 \begin{equation}\label{eq:fciqmcWF}
\ket{\Psi_{\text{CI}}}= C_0\ket{D_0} + \sum_{ai} C_i^a \ket{D_i^a} + \sum_{i<j,a<b}C_{ij}^{ab}\ket{D_{ij}^{ab}} + \dots,
 \end{equation}
here $\ket{D_0}$\footnote{we use $\ket{D_0}$ for $\ket{\Psi_0}$, $\ket{D_i^a}$ for $\ket{\Psi_i^a}$ and so on to distinguish between deterministic and stochastic methods} is HF determinant, $\ket{D_i^a}$ and $\ket{D_{ij}^{ab}}$ are exited determinants.\\
In order to determine coefficients $C$ we need to solve a set of projection equations. 
\begin{align}
\braket{D_0|\hat{H}-E|\Psi_{\text{CI}}}=0\\
\braket{D_i^a|\hat{H}-E|\Psi_{\text{CI}}}=0\\
\braket{D_{ij}^{ab}|\hat{H}-E|\Psi_{\text{CI}}}=0\\
\braket{D_{ijk}^{abc}|\hat{H}-E|\Psi_{\text{CI}}}=0,
\end{align} 
and so on.\\
Instead of performing this process iteratively we now need to re-express equations. As we already mentioned in section $\ref{sec:DMC}$ while describing DMC this can be done using the imaginary time propagator. In this case operator is given by:
\begin{equation}\label{eq:projector} 
\hat{P}=1-\tau(\hat{H}-E).
\end{equation}
It projects CI wave function to itself. Using this approach we will get a new set of equations, formulated as:
\begin{equation}\label{eq:CIprojected}
C_{\textbf{I}} - \tau \braket{D_{\textbf{I}}|\hat{H}-E|D_{\textbf{I}}}C_{\textbf{I}} - \tau \sum_{\textbf{J}\rightarrow \textbf{I},\textbf{J}\neq \textbf{I} }  \braket{D_{\textbf{I}}|\hat{H}|D_{\textbf{J}}}C_{\textbf{J}} = C_{\textbf{I}},
\end{equation}
here $\textbf{I}, \textbf{J}$ are some generic indexes and $\textbf{J}\rightarrow \textbf{I}$ means that this two indexes are connected (corresponding matrix element of Hamiltonian is different from zero).
As in DMC we may study two processes independently, namely:
\begin{align}
C_{\textbf{I}} - \tau \braket{D_{\textbf{I}}|\hat{H}-E|D_{\textbf{I}}}C_{\textbf{I}} \rightarrow C_{\textbf{I}}\\\label{eq:FCIQMC_coef1}
C_{\textbf{I}} - \tau \sum_{\textbf{J}\rightarrow \textbf{I},\textbf{J}\neq \textbf{I} }  \braket{D_{\textbf{I}}|\hat{H}|D_{\textbf{J}}}C_{\textbf{J}} \rightarrow C_{\textbf{I}}\\ \label{eq:FCIQMC_coef2}
\end{align}
After this we need to discretize the coefficients. To simulate this stochastically we should create a population of walkers in the SD space. Each walker has a sign and belog to any determinant. Number of walkers on each specific determinant, e.i. $D_{\textbf{I}}$ is proportional to coefficient $C_{\textbf{I}}$. The population dynamics in this case should obey equations ($\ref{eq:FCIQMC_coef1}$) and ($\ref{eq:FCIQMC_coef2}$).In order to run the simulation we need to consider three processes:\\
\begin{enumerate}
	\item \textbf{Spawning}. Aa soon as walker can be positioned on any determinant, we consider random walker at determinant $D_{\textbf{J}}$.After this we randomly pick up a connected determinant  $D_{\textbf{I}}$ (assuming $|H_{\textbf{IJ}}|\neq 0$). The probability to spawn a walker from $\textbf{J} \rightarrow \textbf{I} $ is proportional to $\tau |H_{\textbf{IJ}}| $ and sign $- sgn(H_{\textbf{IJ}})$. The spawning process is corresponding to equation ($\ref{eq:FCIQMC_coef2}$) and can be formulated as $ - \tau H_{\textbf{IJ}} C_{\textbf{J}} + C_{\textbf{I}} \rightarrow  C_{\textbf{I}} $.
	\item \textbf{Birth/Death}. Here we simulate creation or destruction of the already existing walker at some determinant, for example $D_{\textbf{I}}$ . This process corresponds to the  equation ($\ref{eq:FCIQMC_coef1}$) and the probability is now proportional to $- \tau (H_{\textbf{II}} - E) $ and sign distinguish between either walker is created or destroyed. Negative sign corresponds to death and positive sign corresponds to birth.
	\item \textbf{Annihilation}. All pairs of walkers with opposite sign are removed, if they belong to the same determinant.
\end{enumerate}
The population control is carried out by varying of the remaining parameter, so-called shift $E$. This parameter can influence the population dynamics in a following way - if the value of $E$ exceeds the lowest eigenvalue, then the population of walkers will increase and vice versa. 
\subsection{Coupled Cluster Quantum Monte Carlo}
Following the same procedure as for FCIQMC we present a CC wave function in a similar way as we did it for CI in equation ($\ref{eq:fciqmcWF}$). The CC wave function is represented by the following expansion:
\begin{equation}\label{eq:ccqmcWF}
\ket{\Psi_{\text{CC}}}= N_0 e^{\frac{\hat{T}}{N_0}}\ket{D_0},
\end{equation}
where $N_0$ determines the normalization of wave function and the equation for cluster operator $\hat{T}$ is presented in description of deterministic CC method in Chapter $\ref{ch:coupled_cluster}$ by equation ($\ref{eq:T}$). \\
Let's write it in a more detailed way using a cluster operator equation:
\begin{align}
\ket{\Psi_{\text{CC}}}=N_0\ket{D_0} + \sum_{\textbf{I}} \ket{D_0} t_\textbf{I} \hat{c_\textbf{I}} + \frac{1}{2N_0}
 \sum_{\textbf{IJ}} \ket{D_0} t_\textbf{I} t_\textbf{J}\hat{c_\textbf{I}} \hat{c_\textbf{J}}\ket{D_0} + ...,
\end{align}
where indexes \textbf{I,J} are generic indexes for an excitation.\footnote{Indexing is different from the deterministic CC theory, because we are using notations by Thom and Spenser from \cite{spencerDevelopmentsStochasticCoupled2016}. In this notation each cluster has just one generic index, regardless of level of the excitation for example, $ \hat{c_a}^\dagger \hat{c_i}$ is just written as $\hat{c_\textbf{I}}$.} We use this kind of notations to make equations more alike those for FCIQMC.\\ 
After this we can present the CC equations:
\begin{align}\label{eq:CCQMC1}
&\braket{D_0|\hat{H}-E|\Psi_{\text{CC}}}=0,\\
&\braket{D_i^a|\hat{H}-E|\Psi_{\text{CC}}}=0,\\
&\braket{D_{ij}^{ab}|\hat{H}-E|\Psi_{\text{CC}}}=0,\\
\end{align} 
and so on.\\
\subsubsection{A representative example}
Here we follow Thom in his article from 2010 \cite{thomStochasticCoupledCluster2010} to present a simple idea of CCQMC for a system that has only four states, two occupied (i,j) and two virtual (a,b). Here we use generic index for determinant so that $ \ket{D_{ij}^{ab}} = \ket{D_\textbf{n}} $.
As it has been already done for the FCIQMC we need an operator ($\ref{eq:projector}$) that projects the solution $\Psi_{CC}$ to itself and reproduce the same eigenfunctions.\\
After this we obtain:
\begin{align}
\braket{D_{\textbf{n}|}| 1-\tau (\hat{H}-E)|\Psi_{CC}}, \label{key} \\
\big(1-\tau(H_{\textbf{nn}}-E)\big)\big(t_i^a t_j^b-t_i^b t_j^a + t_{ij}^{ab}\big)  \nonumber \\
- \frac{\tau}{N_0} \sum_{\textbf{m} \neq \textbf{n}} H_{\textbf{nm}} \braket{D_{\textbf{m}}|\Psi_{CC}} = (t_i^a t_j^b-t_i^b t_j^a + t_{ij}^{ab}),
\end{align}
where we consider determinants $D_{\textbf{n}}$ and $D_{\textbf{m}}$ to be connected,so that  $H_\textbf{nm} \neq 0 $. This equation is similar to equation ($\ref{eq:CIprojected}$). Once aging following the same procedure as for FCIQMC we are aiming to create a population of walkers in order to discretize the amplitudes. In case of CCQMC walkers are called "excips" and the corresponding operators are named "excitors" \footnote{Here one should be careful with terminology because it can differ from one article to another. Imaginary particles for stochastic approach to solve the Schr\"{o}dinger equation were first introdused by Andersen article  \cite{andersonRandomWalkSimulation1975} and were called "psips". In this thesis we follow the Thom and Spencer in \cite{spencerDevelopmentsStochasticCoupled2016}  and name operators as "excitors" and particles as "excips". In some articles both particles and operators are addressed to as "excitors".}. In this case excips on the Hartree-Fock determinant are represented by $N_0$ and all the other amplitudes $t_{\textbf{I}}$ are represented by walkers in the excited space. In case of stochastic coupled cluster theory we should consider products of excitors as well as a single ones. Following the notations from the article we use square brackets to do so, $[t_i^a t_j^b ]$, $[t_i^b t_j^a ]$  and $t_{ij}^{ab}$ should by considered separately. \\
Spawn and death steps corresponding to equations are described in a following way:
\begin{align}
\end{align}




The main point here is to generate and store only non-composite clusters. This is achieved as follows:
\begin{itemize}
\item 
\end{itemize} 


SAMPLING




















\chapter{Stochastic}
\section{Normalization}
Our description uses intermediate normalization as an assumption and it requires a normalization constant to be introduced. 
!!!!DOPISAT' POCHEMU!!
\begin{equation}
\ket{\Psi_{\text{CC}}}=N_0 e^{\frac{\hat{T}}{N_0}} \ket{D_0}.
\end{equation}
here $N_0$ is normalization constant.\\
Such normalization allows to produce fractional populations on excitors, needed for convergence.
\section{Sampling probabilities}

We have to sample a wave function. In this case a wave function is approximated by the exponential expansion in terms of cluster operator. We will conduct sampling by selecting a particular cluster from the expansion. Here we need to introduce some definitions.\\


\begin{defn}Cluster size.\\
 Size of a cluster is defined by number of excips that are used to collapse the wave function. Reference determinant is considered as a cluster of size $0$.
\end{defn}
The probability to choose a cluster of certain size is given by

\begin{equation}
	p_{\text{size}} = \frac{1}{2^{s+1}}.
\end{equation}
here $s$ is size of a cluster. \\
Each cluster has it's amplitude $A$.\\
After we have selected a cluster of size $s$, we need another probability - a probability to select a combination of excitors $e$.

\begin{equation}
p_{\text{clust}} (e|s)= s! \prod_{i=1}^s \frac{|N_i|}{N_{ex}}.
\end{equation}

here $|N_i|$ is a population on excitor $i$, module here is needed because population of each excitor is stored with sing and can in some cases be negative.\\
Combining these probabilities together we get:
\begin{equation}
p_{select}(e)= \frac{s!\prod_{i=1}^{s} |N_i|}{2^{s+1}N_{ex}}.
\end{equation}
It is also important that we use sample same number of excips at each time step:
\begin{equation}
p_{sel}= N_0+N_{ex}.
\end{equation}

While sampling we need just these: $\delta \tau$, $A=N_0$, $p_{sel}$, $p_{\text{select}}$ and $p_{\text{clust}}$ and $p_{\text{excit}}$.
\begin{equation}
p_{\text{excit}} = \frac{1}{N_{ex}}. 
\end{equation}

Spawn probability is:
\begin{equation}
p_{\text{total}} = \frac{|\delta \tau H_{nm}A|}{p_{\text{select}}p_{sel}p_{\text{clust}}p_{\text{excit}}} 
\end{equation} 
Death probability is: 
\begin{equation}
p_{\text{death}} = \frac{|\delta \tau (H_{mm} - S)A|}{p_{\text{select}}p_{sel}p_{\text{clust}}} 
\end{equation}




\section{Sampling}

Number of single-, double- and triple-excitations including Pauli exclusion principle are defined by the following formulas:

\begin{equation}\label{eq:num_singles}
N_s = \frac{1}{2}F(N-F)
\end{equation}

\begin{equation}\label{eq:num_doubles}
N_d = \frac{1}{2^4}F(F-2)(N-F)^2
\end{equation}

\begin{equation}\label{eq:num_triples}
N_t = \frac{1}{2^4}F(3F-4)(N-F)^3
\end{equation}
Where $F$ is the Fermi level and $N$ is the number of single-particle states in the system. So we choose single or double proportionally to their amount for a given system configuration.
\begin{equation}
P_1 = \frac{A \delta \tau \bra{D_m}\hat{H} \ket{D_n}}{p_{\text{select}}p_{sel}p_{\text{clust}}p_{\text{excit}}}
\end{equation}
\begin{equation}
P_2 = \frac{A \delta \tau (\bra{D_n}\hat{H} \ket{D_n}-S)}{p_{\text{select}}p_{sel}p_{\text{clust}}}
\end{equation}
where
\begin{equation}
\delta \tau \leq \frac{2}{E_{max} - S}
\end{equation}
where $E_{max}$ is the largest eigenvalue of the most excited determinant available in a given one-electron basis and $S \approx E_0$.\\
Parameter A is known as amplitude total amplitude of the cluster. It depends on size of the cluster.
\begin{equation}
A = N_0  \prod_{i=1}^s \frac{N_i}{N_0}
\end{equation},
where $N_i$ -- is population on the excip number $i$.

We select cluster size according exponential distribution:
\begin{equation}
p_{size}(s)=\frac{1}{2^{s+1}}
\end{equation}

\begin{equation}
p_{\text{clust}} (e|s)= s! \prod_{i=1}^s \frac{|N_i|}{N_{ex}}.
\end{equation}
Represents number of possibilities to choose excitations (excitors) within chosen cluster. Also $N_{ex}$ is total number of excited determinants that can by sampled in the system (doubles, if we choose CCD method). This number can be calculated using equations ($\ref{eq:num_singles}$),($\ref{eq:num_doubles}$) and ($\ref{eq:num_triples}$).

\begin{equation}
p_{select}(e)= p_{size}(s) p_{\text{clust}} (e|s) =  \frac{s!\prod_{i=1}^{s} |N_i|}{2^{s+1}N_{ex}}.
\end{equation}



\begin{equation}
p_{sel}= 1+N_{s}+N_{d}+N_{t}.
\end{equation}
$p_{sel}$ represent a number of samples in each time-step. This parameter must by constant and depend on total number of possible excited determinants combine with reference.


\begin{equation}
p_{\text{excit}} = \frac{1}{N_{ex}}.
\end{equation}
This parameter represent probability to select excited state (not reference).





Lets compute some particular probabilities:\\



\begin{enumerate}
\item For a cluster of size zero:

\begin{align}
p_{size} = \frac{1}{2},\\
p_{sel} = 1+N_{s}+N_{d}+N_{t} = 2N_0,\\
p_{excit}=\frac{1}{N_{ex}} = \frac{1}{N_d}, for doubles\\
A = N_0,\\
p_{clust}=1\\
\delta \tau = \frac{2}{E_m  - S},\\
p_{death}=0, by constraction\\
p_{spawn} = \frac{2}{|E_m  - S|} \frac{|AH_{m0}|}{ p_{sel}  p_{size} p_{clust}p_{excit} }=
\frac{2}{|E_m  - S|} \frac{N_0|H_{m0}|}{ \frac{1}{2}  2N_0 \frac{1}{N_d} }=\\
p_{spawn} = \frac{2N_d|H_{m0}|}{|E_m  - S|} 
\end{align}
 
\item For cluster size 1 we have three possibilities:\\
1) Parent is a singly exited determinant.

\begin{itemize}
	\item no spawn
	\item death according to:
\begin{align}
p_{size} = \frac{1}{4},\\
p_{sel} =  2N_0,\\
p_{excit}= \frac{1}{N_d}\\
A = N_0\frac{N_i}{N_0}=N_i,\\
p_{clust}=1!\frac{1}{N_0}\\
\delta \tau = \frac{2}{E_m  - S},\\
p_{death} = \frac{2}{|E_m - S|} \frac{|A(H_{mm}-S)|}{ p_{sel}  p_{size} p_{clust} }=\\
\frac{4}{|E_m  - S|} \frac{|H_{mm}-S|N_dN_i}{N_0 }
\end{align}
here $N_i$ population on chosen excip $i$. Normally in the beginning of simulation it is $i= +1,-1$.
\end{itemize}

2) Parent is a doubly exited determinant.

\begin{itemize}
\item can spawn only singly excited determinant with probability:
\begin{align}\label{eq:spawn_ziae_1}
p_{spawn} = \frac{2}{E_m - S} \frac{|AH_{mn}|}{ p_{sel}  p_{size} p_{clust} p_{excit} }=\\
\frac{2}{|E_m  - S|} \frac{|H_{mn}|}{2N_0 \frac{1}{4} \frac{1}{N_d} \frac{1}{N_0}} =\\
p_{spawn} =\frac{4|H_{mn}|N_d}{|E_m  - S|}
\end{align}
\item death according to:
\begin{align}
p_{death} = \frac{2}{E_m - S} \frac{|A(H_{mm}-S)|}{ p_{sel}  p_{size} p_{clust} }= \frac{2}{|E_m - S|} \frac{A|H_{mm}-S|N_i}{ 2N_0 \frac{1}{4} \frac{1}{N_0}}=\\
p_{death} = \frac{4|H_{mm}-S|N_i}{|E_m - S|} 
\end{align}
\end{itemize}
3) Parent is a triply exited determinant.
\begin{itemize}
\item can spawn only singly or doubly excited determinant with same probability as before ($\ref{eq:spawn_ziae_1}$).
\item $p_{death} = 1$ as we do not count triples.
\end{itemize}

\item For cluster size 2 we have two possibilities:\\
1) Parent is a doubly exited determinant.
\begin{itemize}
	\item can spawn only singly excited determinant with probability:
\begin{align}
p_{size} = \frac{1}{8},\\
A = N_0\frac{N_i}{N_0}\frac{N_j}{N_0}=\frac{N_jN_i}{N_0},\\
p_{clust}=2!\frac{|N_i|}{N_0}\frac{|N_j|}{N_0}=\frac{2|N_jN_i|}{N_0^2}\\
\delta \tau = \frac{2}{E_m  - S},\\
p_{spawn} = \frac{2}{|E_m - S|} \frac{|A(H_{mn}-S)|}{ p_{sel}  p_{size} p_{clust} p_{excit}  }=\\
p_{spawn} = \frac{2}{|E_m - S|} \frac{  | \frac{N_jN_i}{N_0} (H_{mn}-S)|}{2N_0 \frac{1}{8} \frac{2|N_jN_i|}{N_0^2} \frac{1}{N_d} }=\\
p_{spawn} = \frac{4}{|E_m - S|} \frac{ |\frac{N_jN_i}{N_0} (H_{mn}-S)|}{ \frac{|N_jN_i|}{N_0} \frac{1}{N_d} }=\frac{4|H_{mn}-S|N_d}{|E_m - S|}\label{eq:spawn_ziae_2}
\end{align}
	\item death according to:
\begin{align}
	p_{death} = \frac{2}{E_m - S} \frac{A|H_{mm}-S|}{ p_{sel}  p_{size} p_{clust} }=
	 \frac{2}{E_m - S} \frac{\frac{N_jN_i}{N_0}|H_{mm}-S|}{ 2N_0 \frac{1}{8} \frac{2N_jN_i}{N_0^2} }=\\
	 p_{death} =  \frac{4|H_{mn}-S|}{|E_m - S|}
\end{align}
\end{itemize}
3) Parent is a triply exited determinant.
\begin{itemize}
	\item can spawn only singly or doubly excited determinant with same probability as before ($\ref{eq:spawn_ziae_2}$).
	\item $p_{death} = 1$ as we do not count triples.
\end{itemize}

\item Cluster size 3:

Parent is a triply exited determinant.
\begin{itemize}
	\item can spawn only singly or doubly excited determinant with  probability  
\begin{align}
	p_{size} = \frac{1}{16},\\
	A = N_0\frac{N_i}{N_0}\frac{N_j}{N_0}\frac{N_k}{N_0}=\frac{N_jN_iN_k}{N_0^2},\\
	p_{clust}=3!\frac{|N_i|}{N_0}\frac{|N_j|}{N_0}\frac{|N_k|}{N_0}=\frac{6|N_jN_iN_k|}{N_0^3}\\
	\delta \tau = \frac{2}{E_m  - S},\\
	p_{spawn} = \frac{2}{E_m - S} \frac{|A(H_{mn}-S)|}{ p_{sel}  p_{size} p_{clust} p_{excit}  }=\\
	p_{spawn} = \frac{2}{E_m - S} \frac{\frac{|N_jN_iN_k|}{N_0^2}|H_{mn}-S|}{ 2N_0 \frac{1}{16} \frac{6|N_jN_iN_k|}{N_0^3} \frac{1}{N_d}}= \\
p_{spawn} = \frac{8N_d|H_{mn}-S|}{3(E_m - S)}
\end{align}
	\item $p_{death} = 1$ as we do not count triples.
\end{itemize}
\end{enumerate}
\subsection{Sing Problem}
\chapter{Coulomb matrix elements}
Coulomb matrix elements are required for all methods described in this thesis. In case of Hartree Fock method they can be just computed on the fly, using the formulas presented in Appendix $\ref{app:1}$ . However, after we made a transformation to the Hartree Fock basis, we need they to be stored and assessed in a most quickly and efficient way possible. \\
One solution is to store them as four-dimensional array, mapping the unique set of indexes $pqrs$ to a certain value. This method is inefficient, because due to symmetry requirements such array will contain a lot of zeros.\\
Another solution is to store only non-zero values in one array and associated set of indexes  in the other. This improvement will save a lot of memory, but require a costly search through the vector of indexes, to find a position of needed combination $pqrs$.\\
One more solution is to map each non-zero value with a unique address. This method combine advantages of the two described above and allow us to save both memory and avoid search.\\
The method is described in details here \cite{leikangerFullConfigurationInteraction}.

\part{Implementation and results}
In this part we present the implementation of algorithms presented in the thesis. This part has the following structure:\\
\begin{itemize}
\item Section $\ref{sec:impl1}$ present a general structure of the code and description of all classes used.
\item Section (REF) 
\end{itemize}

\section{General structure of the code}\label{sec:impl1}
Code has the following base classes:
\begin{enumerate}
\item Class \textit{GENERALSPCLASS} is base class and contains the following virtual functions:
	\begin{enumerate}
	\item \textit{getQuantumDotStates},
	\item \textit{getQuantumDotStatesNumber},
	\item \textit{TBME},
	\item \textit{getSPenergies},
	\end{enumerate}
\item \textit{channelset} is another base class with virtual functions:
\end{enumerate}
And following derived classes:

\section{Implementation of Hartree-Fock solver}




% Define block styles
\tikzstyle{decision} = [diamond, draw, fill=blue!20, 
text width=5.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
text width=20em, text centered, rounded corners, minimum height=5em]
\tikzstyle{small block} = [rectangle, draw, fill=blue!20, 
text width=7em, text centered, rounded corners, minimum height=5em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [draw, ellipse,fill=red!20, node distance=3cm,
minimum height=2em]
\begin{figure}
	\centering
\begin{tikzpicture}[node distance = 3cm, auto]
% Place nodes
\node [block] (init) {Compute One-Body and Two-Body matrix elements};
%\node [cloud, left of=init] (expert) {expert};
%\node [cloud, right of=init] (system) {system};
\node [block, below of=init] (identify) {Initialize the coefficient matrix and the density matrix};
\node [block, below of=identify] (initialize) {Compute Hartree-Fock matrix};
\node [block, below of=initialize] (evaluate) {Dizgonalize the Hartree-Fock matrix};  
\node [decision, below of=evaluate] (decide) {Convergence test passed?};
\node [small block, left of=decide, node distance=6cm] (update) {Update the coeficient matrix and Compute new HF matrix};
\node [block, below of=decide, node distance=3cm] (stop) {Compute HF Energy and Store the coeficient matrix};
% Draw edges
\path [line] (init) -- (identify);
\path [line] (identify) -- (initialize);
\path [line] (initialize) -- (evaluate);
\path [line] (evaluate) -- (decide);
\path [line] (decide) -- node [near start] {no} (update);
\path [line] (update) |- (evaluate);
\path [line] (decide) -- node {yes}(stop);
%\path [line,dashed] (expert) -- (init);
%\path [line,dashed] (system) -- (init);
%\path [line,dashed] (system) |- (evaluate);
\end{tikzpicture}
\caption{Flow chart for Hartree-Fock algorithm}\label{fig::FHflowchart}
\end{figure}

Fig. $\ref{fig::FHflowchart}$ present the illustration for the HF algorithm. Here is a bit more detailed description of the algorithm:
\begin{tcolorbox}
	\begin{itemize}
		\item Calculate the one-body $\braket{\alpha|\hat{h}|\beta}$ and two-body $\braket{\alpha\beta|\hat{v}|\gamma\delta}$ matrix elements.  \\
		\item Begin iteration procedure:
		\begin{enumerate}
			\item Start with a guess for coefficient matrix. Usually an identity matrix $C^{(0)}_{i\alpha}$,  and density matrix $\rho^{(0)}_{\gamma\delta}$. For $\alpha, \gamma, \delta \in N_{\text{st}}$ and $i \in N_{p}$ ($N_{\text{st}}$ - number of states and $N_{p}$ - number of particles). 
			\item The Hartree-Fock matrix on first iteration is computed as 
			 \[ \hat{h}^{\text{HF}}_{\alpha \beta}(0) = \epsilon_\alpha \delta_{\alpha\beta} + \sum_{\gamma\delta}^{N_{\text{st}}} \rho^{(0)}_{\gamma\delta} \braket{\alpha\beta|\hat{v}|\gamma\delta}  \] 
			 \item Diagonalize the Hartree-Fock matrix. Compute  $C^{(1)}_{i\alpha}$,   $\rho^{(1)}_{\gamma\delta}$ and $\epsilon_i^{HF}$
			 \item For every iteration check the convergence:
			 \[\frac{\sum_{i}^{N_p} |\epsilon_i^{(n)}- \epsilon_i^{(n-1)}|}{N_{st}} \leq \textbf{tolerance},\]
			 where \textbf{tolerance} usialy a small number ($\approx 10^{-6}$). If convergence test fail compute new $\hat{h}^{\text{HF}}_{\alpha \beta}$ matrix and repeat the procedure.			 	
		\end{enumerate} 
		\item After the convergence test is passed, compute the HF energy and store the last version of coefficient matrix. 
	\end{itemize}
\end{tcolorbox}

\subsection{Code structure for HF}

\begin{figure}
\begin{lstlisting}[language=C++]
void qdotHFbasis::fillTwoBodyElements(){
	int NumberOfStates = m_shells.size();	
	for(int i = 0; i < NumberOfStates; i++) {
		qstate quantum_state_alpha = m_shells.at(i);
		int alpha_n = quantum_state_alpha.n();
		int alpha_m = quantum_state_alpha.m();
		int alpha_sm = quantum_state_alpha.s();
			
		for(int j = 0; j < NumberOfStates; j++) {
			qstate quantum_state_beta = m_shells.at(j);
			int beta_n = quantum_state_beta.n();
			int beta_m = quantum_state_beta.m();
			int beta_sm = quantum_state_beta.s();
			
			for(int k = 0; k < NumberOfStates; k++) {
				qstate quantum_state_gama = m_shells.at(k);
				int gama_n = quantum_state_gama.n();
				int gama_m = quantum_state_gama.m();
				int gama_sm = quantum_state_gama.s();
					
					for(int l = 0; l < NumberOfStates; l++) {
						qstate quantum_state_delta = m_shells.at(l);
						int delta_n = quantum_state_delta.n();
						int delta_m = quantum_state_delta.m();
						int delta_sm = quantum_state_delta.s();
							
							if (alpha_sm == beta_sm && gama_sm == delta_sm ){
								m_twoBodyElements[i][k][j][l] = Coulomb_HO(homega, alpha_n, alpha_m, gama_n, gama_m, beta_n, beta_m,  delta_n, delta_m);
							}
							if ((alpha_sm == delta_sm && gama_sm == beta_sm )){
								m_twoBodyElements[i][k][l][j] = Coulomb_HO(homega, alpha_n, alpha_m, gama_n, gama_m, delta_n, delta_m, beta_n, beta_m);
							}
						}
					}
				}
			}
		}
\end{lstlisting}
\caption{Fill two-body elements}
\end{figure}

\begin{figure}
\begin{lstlisting}[language=C++]
void qdotHFbasis::computeHFmatrix(arma::mat DensityMatrix){
	int NumberOfStates = m_shells.size();
	m_HF.zeros(NumberOfStates,NumberOfStates);
	double FockElement = 0;
	
	for(int i = 0; i < NumberOfStates; i++) {
		for(int j = 0; j < NumberOfStates; j++) {
			for(int k = 0; k < NumberOfStates; k++) {
				for(int l = 0; l < NumberOfStates; l++) {
					FockElement += DensityMatrix(k,l)*TBME(i,k,j,l);
					if (FockElement !=0.0){
					}
				}
			}
			if (i == j) {
				m_HF(i, i) += m_HOEnergies.at(i);
			}
			m_HF(i, j) += FockElement;
			FockElement = 0.0;
		}
	}
}
\end{lstlisting}
\caption{Compute HF matrix}
\end{figure}
\subsection{Channels for CCD}

\begin{figure}
\begin{lstlisting}[language=C++]
for(int Ml = -Mlmax; Ml <= Mlmax; Ml++){
for(int S = -Smax; S <= Smax; S = S + 2){
i++;
ChannelVariety.emplace_back(channel());

for(int i = 0; i < qsys->getFermiLevel(); i++){
for(int j = 0; j < qsys->getFermiLevel(); j++){
qstate *QuantumState = qsys->sumState(i,j);
if(Ml == QuantumState->m() && S == QuantumState->s() && i != j){
ChannelVariety.back().m_HoleHoleVec.emplace_back(channelindexpair());
ChannelVariety.back().m_HoleHoleVec.back().set(i, j);
} delete QuantumState;

\end{lstlisting}
\caption{Setting up channels}
\end{figure}

\clearpage
**\appendix
\chapter{Coulomb matrix elements}\label{app:1}




\printbibliography 



\end{document}